[
  {
    "text": "[Page 1]\nChapter 4: Results and Discussion  \n4.1 Introduction  \nThis chapter presents a comprehensive analysis and in -depth discussion of the empirical results \nobtained from the simulation framework, the design and mechanics of which were meticulously \ndetailed in Chapter 3: Methodology. The overarching aim of this rese arch, as stated in Chapter \n1: Introduction, is to critically analyze and propose effective strategies for optimizing video \nstreaming latency. A core focus is to unravel and quantify the factors contributing to latency \ndiscrepancies experienced by users und er heterogeneous network conditions, a challenge \nparticularly pronounced in dynamic mobile environments. The simulations, forming the \nbackbone of this empirical investigation, were specifically engineered to evaluate the \nperformance of Adaptive Bitrate (AB R) streaming algorithms. Particular attention is given to the \ncustom -developed LatencyAwareAbr , which was tested against a backdrop of realistic \nbandwidth conditions derived from real -world mobile network traces and synthetically varied \nRound -Trip Times (R TTs) to mimic diverse user network paths.  \nThe findings of this chapter will be articulated through a synergistic combination of aggregated \nKey Performance Indicators (KPIs), providing a quantitative snapshot of performance, and \ndetailed time -series plots, which offer a granular view of the dynamic behavior of the simulated \nstreaming clients over time. The ensuing discussion will pivot around interpreting these findings \nin direct relation to the research questions and objectives posited in Chapter 1. Specifi cally, this \nchapter seeks to address:  \n1. The quantifiable impact of network RTT on various facets of perceived playback latency \n(including startup delay, stall duration, and overall playback progression) and its \ncascading effects on the holistic Quality of Ex perience (QoE).  \n2. The magnitude and dynamics of the playback time difference (referred to as viewer \ndiscrepancy or relative latency) between simulated clients operating with low versus high \nRTTs, a critical factor for synchronized or live viewing experiences . \n3. A detailed performance assessment and behavioral analysis of the LatencyAwareAbr  \nalgorithm, examining its adaptiveness and efficacy under these varied and often \nchallenging network conditions.  \n4. The broader implications of these findings for the design and  implementation of more \nrobust and effective latency optimization strategies in the domain of mobile video \nstreaming, potentially informing future algorithm development as discussed in relation to \nObjective 3 in Chapter 1.  \n5. How these results align with or d iverge from existing knowledge as reviewed in Chapter \n2: Literature Review, and how they contribute to bridging identified gaps.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 0,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "n to \nObjective 3 in Chapter 1.  \n5. How these results align with or d iverge from existing knowledge as reviewed in Chapter \n2: Literature Review, and how they contribute to bridging identified gaps.\n\n[Page 2]\n4.2 Simulation Setup and Parameters: A Brief \nRecapitulation  \nTo ensure clarity and context for the results presented, this secti on briefly revisits the crucial \ncomponents of the simulation environment, as exhaustively defined in Section 3.2: Data \nCollection Methods and Section 3.3: Algorithm Development of Chapter 3.  \n1. Adaptive Bitrate (ABR) Algorithms Under Test:  \ni. LatencyAwareAbr : This is the central ABR algorithm developed and evaluated \nin this study. Its design philosophy, detailed in Section 3.3.1: Latency -Aware \nAdaptation Logic, explicitly incorporates network delay (RTT) into its bitrate \nselection process. It leverages simple pre dictive techniques for both throughput \n(harmonic mean of recent measurements) and delay (moving average), and \nemploys a defined conservative buffer threshold \n(LATENCY_AWARE_CONSERVATIVE_BUFFER_S ) to govern quality upshifting \ndecisions, aiming to balance ag gressiveness with stability.  \nii. (Implicitly, results from LatencyAwareAbr  could be benchmarked against a \nmore traditional BufferBasedAbr  or other algorithms outlined in Chapter 2, \nthough the primary focus here is on the differential impact of RTT on clients u sing \nLatencyAwareAbr .) \n2. Bandwidth Traces (Source of Realism):  \ni. To ensure ecological validity, real -world HSDPA (High -Speed Downlink Packet \nAccess) mobile network bandwidth traces were employed. These traces, sourced \nfrom the publicly available repository at skulddata.cs.umass.edu  (similar to \nthe MONROE dataset mentioned in Section 3.2.1), capture the inherent \nvariability of mobile network capacity.  \nii. The specific traces forming the basis of the results in this chapter are:  \n\u25a0 Bus: Captures bandwidth dynamics typic al of vehicular movement within \nurban or suburban landscapes, characterized by moderate to high \nvariability.  \n\u25a0 Metro-Tunnel : Represents a highly challenging scenario with periods of \nsevere signal degradation and potential complete loss of connectivity, \ncommo n in underground transit.  \n\u25a0 Train-Fast : Simulates conditions on a faster -moving train, likely \nfeaturing frequent cell handovers and a mix of open -air and potentially \nobstructed signal paths.  \n3. Client Configurations for Latency Discrepancy Analysis:  \ni. A key exper imental design element, directly addressing the project's focus on \nviewer latency differences, involved simulating two primary client profiles for each \nbandwidth trace. These clients shared the identical bandwidth input but were \nsubjected to distinct netwo rk delay characteristics:",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 1,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "fferences, involved simulating two primary client profiles for each \nbandwidth trace. These clients shared the identical bandwidth input but were \nsubjected to distinct netwo rk delay characteristics:\n\n[Page 3]\n\u25a0 Client1_LowLatency : Configured with a base RTT of 30ms, with \nfluctuations up to 50% of this base, simulating a user with a relatively \ngood network path.  \n\u25a0 Client2_HighLatency : Configured with a significantly higher base \nRTT of 150ms, with fluctuations up to 30% of its base, simulating a user \nwith a poorer, higher -latency network path.  \nii. Crucially, for the direct comparison of RTT impact, both clients utilized the same \nLatencyAwa reAbr  algorithm. This experimental control ensures that observed \ndifferences in performance and playback progression are primarily attributable to \nthe RTT differential rather than ABR logic differences.  \n4. Key Performance Indicators (KPIs) and Metrics for Eva luation:  \ni. The evaluation framework, as described in Section 3.4.1: Objective Evaluation \nMetrics, relies on a suite of quantitative KPIs:  \n\u25a0 Startup Delay (seconds): Time from request to first frame playback.  \n\u25a0 Total Stall Time (seconds) and Buffering Ratio (% of playback time spent \nstalled).  \n\u25a0 Average Selected Bitrate (kbps): Average video quality delivered during \nactive playback.  \n\u25a0 Number of Quality Switches and Switches per Minute: Indicators of \nplayback stability . \n\u25a0 A Simple QoE Score: A composite metric attempting to holistically \ncapture user experience, factoring in bitrate benefits and penalties for \nimpairments.  \n\u25a0 Per-Step Playback Time (seconds): Logged at each simulation timestep \n(TIME_STEP_S ), this forms the bas is for calculating the crucial Playback \nLatency Difference (seconds) between Client1_LowLatency  and \nClient2_HighLatency . \n5. Simulation Granularity and Duration:  \ni. Simulations proceeded with a TIME_STEP_S  of 0.1 seconds.  \nii. The total SIMULATION_DURATION_S  for each run was dynamically set to the \nlength of the loaded bandwidth trace, ensuring full utilization of the empirical \nnetwork data.  \n4.3 Analysis of Aggregated Key Performance Indicators \n(KPIs)  \nAggregated KPIs offer a high -level, quantitative comparison of client  performance under the \ndifferent RTT profiles across the spectrum of tested network traces. Table 4.1, derived from the \nsimulation output, summarizes the average metrics for Client1_LowLatency  and \nClient2_HighLatency , both employing the LatencyAwareAbr  algorithm, averaged over \nthe Bus, Metro -Tunnel, and Train -Fast traces. The metrics for individual traces were also",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 2,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "Client1_LowLatency  and \nClient2_HighLatency , both employing the LatencyAwareAbr  algorithm, averaged over \nthe Bus, Metro -Tunnel, and Train -Fast traces. The metrics for individual traces were also\n\n[Page 4]\npresented in the raw simulation output and will be referred to when discussing specific trace \nbehaviors.  \nTable 4.1: Average Performance Metrics Across Traces (ABR: LatencyAware)  \nClient Configuration  Avg \nStartup \nDelay (s)  Avg \nTotal \nStall \nTime (s)  Avg \nBuffering \nRatio (%)  Avg \nAverage \nBitrate \n(kbps)  Avg Quality \nSwitches  Avg \nSimple \nQoE \nScore  \nClient1_LowLatency  1.50 209.53  13.45  967 18.7 -11.1 \nClient2_HighLatency  1.73 211.40  13.86  802 13.7 -14.0 \n4.3.1 Startup Delay: The Initial Hurdle  \nObservation: A consistent and notable finding is that Client1_LowLatency  achieved a lower \nstartup delay compared to Client2_HighLatency  in every individual trace and consequently, \non average (1.50s for Client1 vs. 1.73s for Client2 \u2013 a difference of 0.23 seconds or \napproximately 15% relative to Client1's startup).  \ni. Bus Trace:  Client1: 1.3s, Client2: 1.5s (Difference: 0.2s)  \nii. Metro -Tunnel Tra ce: Client1: 2.0s, Client2: 2.3s (Difference: 0.3s)  \niii. Train -Fast Trace:  Client1: 1.2s, Client2: 1.4s (Difference: 0.2s)  \nDiscussion and Interpretation: This observation directly aligns with theoretical expectations. The \nstartup phase of video streaming involv es fetching an initial set of video segments to meet the \nMIN_BUFFER_TO_START_S  threshold (3 seconds in this configuration). Each of these initial \nsegment downloads \u2013 comprising a request, server processing (assumed minimal and constant \nhere), and data tran sfer \u2013 is subject to the end -to-end network RTT. For \nClient2_HighLatency , with its substantially higher base RTT (150ms vs. 30ms for Client1), \neach of these crucial initial transactions inherently takes longer. Even if the available bandwidth \nwere infinite , the RTT imposes a minimum time for each segment's metadata exchange and \nfirst-byte arrival. The LatencyAwareAbr , despite its name, cannot circumvent this fundamental \nnetwork characteristic during the initial buffering phase, as its primary role is to sel ect \nappropriate bitrates, not to alter the underlying network path delay.  \nThe observed difference of 0.2 -0.3 seconds, while numerically small, represents a tangible \ndelay in the user's perception of service responsiveness. In a competitive streaming market , \nsuch initial delays can contribute to user frustration and abandonment, as highlighted by studies",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 3,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "ngible \ndelay in the user's perception of service responsiveness. In a competitive streaming market , \nsuch initial delays can contribute to user frustration and abandonment, as highlighted by studies\n\n[Page 5]\nreferenced in Chapter 2. This finding underscores that RTT directly impacts one of the most \ncritical initial QoE metrics.  \n4.3.2 Buffering Ratio and Stall Events: The Quest for Smoothness  \nObservation:  \n1. On average, across the three traces, Client1_LowLatency  experienced a marginally \nlower (better) buffering ratio of 13.45% compared to Client2_HighLatency 's 13.86%. \nThis indicates  that, overall, the lower RTT client spent slightly less of its playback \nduration in a stalled state.  \n2. The performance varied significantly by trace:  \ni. The Metro-Tunnel  trace proved exceptionally challenging, inducing high \nbuffering ratios for both clients (C lient1: 22.94%, Client2: 24.74%).  \nii. In the Bus trace, both clients exhibited low buffering ratios, with \nClient2_HighLatency  surprisingly performing slightly better (2.55% vs. \n2.71% for Client1).  \niii. Similarly, in the Train-Fast  trace, Client2_HighLatency  had a s lightly \nlower buffering ratio (14.29% vs. 14.72% for Client1).  \nDiscussion and Interpretation: Stalling is a severe impairment to QoE. The LatencyAwareAbr  \nattempts to prevent stalls by dynamically adjusting the bitrate based on predicted throughput, \nRTT, an d buffer levels. The generally better average performance of Client1_LowLatency  \ncan be attributed to its ability to react more nimbly to network fluctuations. A lower RTT means \nthat the ABR receives feedback on actual download speeds (used for throughput p rediction) \nand completes segment downloads faster relative to the playback rate. This allows it to make \nmore timely decisions to down -switch bitrate if bandwidth deteriorates, thus protecting the buffer \nmore effectively.  \nThe instances where Client2_HighLat ency  showed a slightly better  buffering ratio on \nindividual traces (Bus, Train -Fast) are intriguing. This could be an artifact of the \nLatencyAwareAbr 's behavior under specific conditions. Aware of its inherently higher RTT, \nthe ABR for Client2 might adopt a more consistently conservative bitrate strategy throughout \nthose particular traces. By rarely attempting higher, riskier bitrates, it might avoid some buffer \nunderruns that Client1 (which might attempt higher bitrates more often) could encounter during \nbrief, sharp bandwidth dips. This points to a complex trade -off: the higher RTT client might \nachieve slightly fewer stalls in some  scenarios by sacrificing bitrate more consistently, a \nbehavior amplified by an RTT -sensitive ABR. However, the significantly w orse performance in \nthe Metro -Tunnel trace for Client2 indicates that this conservative approach breaks down when \nbandwidth becomes extremely scarce or volatile, as the high RTT then severely hampers even \nthe download of low -bitrate segments and stall reco very. The prolonged re -buffering times due \nto high RTT after a stall are a critical factor.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 4,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "volatile, as the high RTT then severely hampers even \nthe download of low -bitrate segments and stall reco very. The prolonged re -buffering times due \nto high RTT after a stall are a critical factor.\n\n[Page 6]\n4.3.3 Average Selected Bitrate: The Quality Dimension  \nObservation: A striking and consistent result is that Client1_LowLatency  achieved a \nsubstantially higher avera ge selected bitrate than Client2_HighLatency  across all tested \nscenarios. On average, Client1 delivered 967 kbps versus 802 kbps for Client2 \u2013 a ~20.5% \nadvantage for the low -latency client.  \n1. Bus Trace:  Client1: 1561 kbps, Client2: 1315 kbps (Difference: ~24 6 kbps, 18.7% higher \nfor Client1)  \n2. Metro -Tunnel Trace:  Client1: 670 kbps, Client2: 516 kbps (Difference: ~154 kbps, 29.8% \nhigher for Client1)  \n3. Train -Fast Trace:  Client1: 669 kbps, Client2: 573 kbps (Difference: ~96 kbps, 16.8% \nhigher for Client1)  \nDiscussion and Interpretation: This metric clearly demonstrates the quality advantage conferred \nby lower RTT when using an RTT -aware ABR. The LatencyAwareAbr 's logic, which estimates \nsegment download times by incorporating predicted RTT ( estimated_download _time_s = \nest_transmission_time_s + predicted_delay_s ), naturally becomes more \nconservative when predicted_delay_s  is high. For Client1_LowLatency , the smaller \npredicted_delay_s  means that for any given predicted throughput, the total estimated \ndownload ti me for a higher quality (larger) segment is shorter. This gives the ABR more \nconfidence to select higher bitrates, especially when the buffer is healthy and above the \nLATENCY_AWARE_CONSERVATIVE_BUFFER_S . The quicker feedback loop also allows Client1 \nto mor e rapidly confirm that a higher bitrate is sustainable.  \nConversely, for Client2_HighLatency , the larger predicted_delay_s  inflates the \nestimated download time for all segments. To maintain the critical condition \nsafe_estimated_download_time_s < self.segmen t_duration  (i.e., download faster \nthan playback) or to avoid significant buffer drain, the ABR is often forced to select lower bitrate \nsegments. This is a direct consequence of the ABR attempting to operate safely given the \nhandicap of higher RTT. This fin ding is crucial as it shows RTT not only impacts delay -related \nmetrics but also indirectly forces a reduction in delivered video quality to maintain stability.  \n4.3.4 Quality Switches: The Stability of Adaptation  \nObservation: On average, Client2_HighLatency  performed fewer quality switches (13.7) \ncompared to Client1_LowLatency  (18.7).  \nDiscussion and Interpretation: While fewer switches are often associated with a smoother, less \njarring viewing experience, this result needs careful interpretation in context. Given that \nClient2_HighLatency  operated at consistently lower average bitrates, it had less \"room\" to \nswitch upwards. An ABR that is constrained to lower quality tiers due to network limitations \n(including high RTT that makes higher bitrates risky) will na turally exhibit fewer switches.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 5,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "s \"room\" to \nswitch upwards. An ABR that is constrained to lower quality tiers due to network limitations \n(including high RTT that makes higher bitrates risky) will na turally exhibit fewer switches.\n\n[Page 7]\nClient1_LowLatency , by virtue of being able to explore and utilize a wider range of higher \nbitrates due to its more favorable RTT, encounters more opportunities and necessities to adapt \nits quality level in response to the i nherent fluctuations in mobile bandwidth. Therefore, the \nhigher switch count for Client1 is likely a byproduct of its more dynamic and aggressive (in a \npositive sense) adaptation to maximize quality, rather than an indication of inherent instability. \nThe LatencyAwareAbr  for Client2, being more conservative due to high RTT, likely stayed \nlonger at safer, lower bitrates.  \n4.3.5 Simple QoE Score: An Overall Performance Proxy  \nObservation: Client1_LowLatency  generally registered a better Simple QoE Score \n(Average : -11.1) compared to Client2_HighLatency  (Average: -14.0). Both clients received \nstrongly negative scores in the highly challenging Metro -Tunnel and Train -Fast traces, signifying \na poor overall user experience in those scenarios.  \nDiscussion and Interpretat ion: The Simple QoE Score, as defined (bitrate reward minus \npenalties for startup delay, buffering, and switches), encapsulates the trade -offs discussed \nabove. For Client1_LowLatency , the substantial benefit from higher average bitrates and \nslightly lower startup delay typically offset any minor penalties from a higher number of switches \nor comparable buffering in specific traces. This resulted in a superior QoE score. The very low \n(negative) QoE scores for both clients in the Metro -Tunnel and Train -Fast tr aces are indicative \nof the severe limitations imposed by those network environments. They underscore that even an \nadvanced, RTT -aware ABR strategy can only mitigate, not eliminate, the detrimental effects of \nprolonged periods of extremely low bandwidth. Th e primary value of the ABR in such cases \nshifts from maximizing quality to minimizing debilitating stalls, a task made harder by high RTT. \nThese findings align with the general understanding from Chapter 2 that user QoE degrades \nsharply with increased stal ling and reduced bitrate.  \n4.4 Detailed Analysis of Playback Latency Discrepancy \nand Client Behavior  \nBeyond aggregated KPIs, the time -series plots offer a granular view of the dynamic interplay \nbetween network conditions, ABR decisions, and client playback progression. The \"Client \nPlayback & Latency Difference\" plots are particularly illuminating for the project's core focus on \nviewer discrepancy.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 6,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "network conditions, ABR decisions, and client playback progression. The \"Client \nPlayback & Latency Difference\" plots are particularly illuminating for the project's core focus on \nviewer discrepancy.\n\n[Page 9]\n \nAnalysis of Bus Trace (Plots 4.1 & 4.2):  \n1. Playback Latency Difference (Plot 4.1 - Red Line):  \ni. Client1_LowLatency  (dotted blue line, main Y -axis) quickly establishes a \nplayback lead over Client2_HighLatency  (dashed orange line, main Y -axis) \nwithin the first few seconds. This initial lead, around 0.2 seconds, is primarily due \nto Client1's faster startup time (1.3s vs. 1.5s for Client2).  \nii. The critical event occurs around the 300 -second mark. Plot 4.1 shows the red \nline (difference) sharply decreasing to approximately -2.1 seconds. This indicates \nClient1_LowLatency  is now 2.1 seconds ahead of Client2_HighLatency . \niii. Correlating with Plot 4.2 (Client Behavior - Bus):  \n\u25a0 Network Conditions (Top Panel): At ~300s, while th e shared bandwidth \n(blue solid) is relatively stable and high (around 4000 -5000 kbps), the \nRTT for Client2 (green dashed) is fluctuating around its 150ms base, \nwhereas Client1's RTT (red dashed) is much lower.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 7,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "width \n(blue solid) is relatively stable and high (around 4000 -5000 kbps), the \nRTT for Client2 (green dashed) is fluctuating around its 150ms base, \nwhereas Client1's RTT (red dashed) is much lower.\n\n[Page 10]\n\u25a0 Player Buffer (Second Panel): Just before 300s , Client2's buffer (orange) \ndips significantly, nearly to zero, while Client1's buffer (blue) remains \nhigh.  \n\u25a0 Bitrate Selection (Third Panel): Client1 is at 2500 kbps. Client2, after its \nbuffer dip, drops its bitrate sharply from 2500 kbps down to 750 kbps a nd \nthen briefly to 300 kbps.  \n\u25a0 Player State (Bottom Panel): Client2 enters a brief STALLED  state \n(orange line spikes to \"STALLED\" level) around 300s, while Client1 \nremains PLAYING . \niv. This sequence clearly illustrates how, despite good available bandwidth, the \nhigher RTT and its impact on download predictability and buffer management for \nClient2 led to a stall and a significant drop in quality. Client1, with lower RTT, \nnavigated this period smoothly.  \nv. Subsequently, the ~2 -second playback lead for Client1 is large ly maintained for \nthe remainder of the trace, indicating a persistent discrepancy.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 8,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "ith lower RTT, \nnavigated this period smoothly.  \nv. Subsequently, the ~2 -second playback lead for Client1 is large ly maintained for \nthe remainder of the trace, indicating a persistent discrepancy.\n\n[Page 11]\n \nAnalysis of Metro -Tunnel Trace (Plots 4.3 & 4.4):  \n\u25cf Playback Latency Difference (Plot 4.3 - Red Line):  \n\u25cb This trace showcases a dramatic divergence. After an initial perio d where both \nclients struggle but Client1 maintains a slight lead, Client1 starts to pull \nsignificantly ahead around the 650 -second mark. The red line rises sharply, \nindicating Client1_LowLatency  is progressively getting further ahead of \nClient2_HighLatenc y. The difference peaks at over 18 seconds.  \n\u25cb Correlating with Plot 4.4 (Client Behavior - Metro -Tunnel):  \n\u25a0 Network Conditions (Top Panel): This trace is characterized by extremely \nvolatile and often very low bandwidth (blue solid line frequently near \nzero). C lient2's RTT (green dashed) is consistently higher than Client1's \n(red dashed).  \n\u25a0 Player Buffer (Second Panel): Both clients experience severe buffer \nissues. However, Client2's buffer (orange) depletes more frequently and \nstays near zero for longer durations compared to Client1's (blue), \nespecially from ~650s onwards.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 9,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "ts experience severe buffer \nissues. However, Client2's buffer (orange) depletes more frequently and \nstays near zero for longer durations compared to Client1's (blue), \nespecially from ~650s onwards.\n\n[Page 12]\n\u25a0 Bitrate Selection (Third Panel): Both clients are forced to very low bitrates \n(often 300 kbps). Client2 appears to be stuck at the lowest bitrate for \nlonger periods or fails to download even that successfully.  \n\u25a0 Player State (Bottom Panel): Client2_HighLatency  endures \nextensi ve periods in the STALLED  state. While Client1 also stalls, its \nrecovery is comparatively better, allowing it to accumulate playback time \nwhile Client2 is frozen.  \n\u25cb The combination of abysmal bandwidth and higher RTT proves devastating for \nClient2_HighLatenc y. The higher RTT compounds the difficulty of fetching \neven small, low -bitrate segments when bandwidth is scarce, leading to prolonged \ninability to re -buffer and resume playback. This directly results in the massive \nplayback time discrepancy.\n\n[Page 14]\n \nAnalysis of Train -Fast Trace (Plots 4.5 & 4.6):  \n1. Playback Latency Difference (Plot 4.5 - Red Line):  \ni. The latency difference in this trace is more dynamic than in the Bus trace but less \nextreme than in Metro -Tunnel. Client1 again secures an early lead.  \nii. Between approxi mately 600 -800 seconds, Client1 is consistently about 5 \nseconds ahead. Plot 4.6 shows that during this period, Client2 (orange) selects \nlower bitrates and its buffer is more volatile than Client1's (blue).  \niii. A significant stall by Client2 around 800 seconds (visible in Player State, Plot 4.6) \nallows Client1 to extend its lead.  \niv. Later, around 2000 -2200 seconds, both clients encounter severe network \ndifficulties. Client1 still manages to be up to ~7 seconds ahead as Client2 stalls \nmore. However, periods where Cl ient1 also stalls allow Client2 to reduce the gap,",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 10,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "clients encounter severe network \ndifficulties. Client1 still manages to be up to ~7 seconds ahead as Client2 stalls \nmore. However, periods where Cl ient1 also stalls allow Client2 to reduce the gap,\n\n[Page 15]\nand even briefly results in a negative difference (Client2 ahead) when Client1 \nsuffers a more prolonged stall during a period of universally dire network \nconditions.  \nv. This trace illustrates that while lower RTT generally provides an advantage, \nsevere, sustained bandwidth limitations can affect both clients profoundly, though \nthe lower RTT client often recovers or mitigates damage more effectively.  \nSynthesis of Discrepan cy Observations: The detailed trace analyses consistently demonstrate \nthat: \n1. RTT is a Differentiator: Even with the same ABR logic and shared bandwidth, clients \nwith higher RTT fall behind in playback progression.  \n2. Magnitude Varies with Bandwidth Profile: Th e extent of this discrepancy is heavily \nmodulated by the available bandwidth. In relatively stable, good bandwidth conditions \n(parts of Bus trace), the difference is smaller. In highly volatile or poor bandwidth \nconditions (Metro -Tunnel, parts of Train -Fast), the difference can become extremely \nlarge.  \n3. Compounding Effects: High RTT exacerbates the negative impact of low or fluctuating \nbandwidth by slowing down ABR reactions, segment fetches, and stall recovery.  \n4. LatencyAwareAbr  Behavior: The LatencyAwareAbr  does react to the different \nRTTs, often leading the higher -RTT client to adopt more conservative bitrate strategies. \nWhile this might occasionally help in buffer stability for that client in some  moderate \nconditions, it doesn't prevent it from lagging in pl ayback time and often results in lower \ndelivered quality.  \nThese findings directly support the problem statement in Chapter 1 (Section 1.2) regarding \nsuboptimal QoE and latency issues in mobile networks, particularly highlighting the often -\noverlooked impact  of network delay beyond just bandwidth.  \n4.7 Deeper Dive into LatencyAwareAbr  Algorithm \nPerformance  \nThe primary goal of the LatencyAwareAbr  was to make more informed decisions by \nconsidering RTT. The \"Client Behavior Comparison\" plots allow a closer look a t its operational \ncharacteristics.  \nAnalysis of Buffer Management and Conservative Upshifting:  \n\u25cf The LATENCY_AWARE_CONSERVATIVE_BUFFER_S  (5 seconds, purple dotted line in \nbuffer plots) was intended as a threshold to make upshifting decisions more cautiously.  \n\u25cf Observation: In many instances, especially for Client1_LowLatency , the buffer level \nwas maintained well above this threshold, allowing for more aggressive bitrate",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 11,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "ting decisions more cautiously.  \n\u25cf Observation: In many instances, especially for Client1_LowLatency , the buffer level \nwas maintained well above this threshold, allowing for more aggressive bitrate\n\n[Page 16]\nexploration. For Client2_HighLatency , the buffer frequently hovered closer to or \ndipped below  this threshold, particularly before quality drops or stalls.  \n\u25cf Discussion: This suggests the conservative threshold is active. However, its fixed nature \nmight be a limitation. For instance, when RTT is very high (Client2), a 5 -second \nconservative buffer mig ht still not be conservative enough  because the time to download \nthe next segment (even a low -quality one) plus the RTT could consume more than this \nbuffer if bandwidth suddenly plummets. Conversely, if RTT is low and bandwidth is \nconsistently high, a 5 -second threshold might be too conservative, delaying beneficial \nupshifts. This points to a potential area for refinement: dynamically adjusting this \nconservative threshold based on current RTT levels and/or its observed stability, a \nconcept related to the ad vanced adaptation strategies discussed in Section 2.3.3 and \n2.3.4 of Chapter 2.  \nAnalysis of Bitrate Selection Logic:  \n\u25cf The core logic safe_estimated_download_time_s < self.segment_duration  \nis fundamental. The LatencyAwareAbr  uses predicted throughput and pre dicted delay \nto estimate this.  \n\u25cf Observation: The plots show that Client2_HighLatency  consistently selected lower \nbitrates. This is a direct outcome of its higher predicted_delay_s  contributing to a \nlarger safe_estimated_download_time_s . To satisfy the condi tion of downloading \nfaster than playback, it was forced to choose smaller (lower bitrate) segments.  \n\u25cf Discussion: This demonstrates the RTT -awareness is functioning as designed. However, \nthe accuracy of _predict_throughput()  (harmonic mean) and \n_predict_dela y() (moving average) is crucial. Mobile networks can exhibit rapid, \nnon-linear changes. If these predictions lag significantly behind actual conditions, the \nABR can make suboptimal decisions. For example, if bandwidth drops sharply but the \nprediction is st ill optimistic, the ABR might choose too high a bitrate, leading to a stall, \nespecially if high RTT further delays the download. This reinforces the potential benefit \nof more sophisticated predictive models, potentially machine learning -based, as alluded \nto in Section 3.3.2.  \nResilience and Recovery:  \n\u25cf Observation: Client1_LowLatency  generally recovered from buffer depletions or \nstalls faster than Client2_HighLatency . \n\u25cf Discussion: This is due to two factors: (1) Its lower RTT means segment fetches during \nre-buffering are quicker. (2) Its ability to achieve higher throughput (due to better ABR \ndecisions based on quicker feedback) also aids faster buffer replenishment. The \nLatencyAwareAbr  doesn't have an explicit \"fast recovery\" mode, but the natural \nconsequence o f better network conditions for Client1 facilitates this.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 12,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "ck) also aids faster buffer replenishment. The \nLatencyAwareAbr  doesn't have an explicit \"fast recovery\" mode, but the natural \nconsequence o f better network conditions for Client1 facilitates this.\n\n[Page 17]\n4.8 Discussion: Connecting Results to Research \nObjectives and Literature  \nThe empirical results presented provide substantial evidence to address the research questions \nand objectives set forth in this study.  \nAddressing Latency Factors and Viewer Discrepancy (Objective 1 from Chapter 1 and Problem \nStatement): The simulations hav e unequivocally quantified the detrimental impact of increased \nRTT on key performance metrics (startup delay, average bitrate, overall QoE) and, most \ncritically, on the playback latency discrepancy between users. The difference of up to 18 \nseconds observed  in the Metro -Tunnel trace is a stark illustration of how varied network paths \ncan lead to vastly different viewing experiences, a direct challenge to the viability of \nsynchronized co -viewing or timely live event consumption. This empirically validates the  \nconcerns raised in Section 1.2 (Statement of the Problem) about high latency degrading QoE.  \nEvaluating the LatencyAwareAbr  (Objective related to ABR development): The \nLatencyAwareAbr , by design, demonstrated sensitivity to RTT. It forced the higher -RTT cl ient \ninto more conservative bitrate selections, which is a rational adaptive response to mitigate risks \nassociated with longer feedback and download times. However, its performance under severe \nconditions (Metro -Tunnel) and the simplicity of its predictive  components indicate clear avenues \nfor improvement, aligning with the goal of proposing an optimized video delivery framework \n(Objective 3 in Chapter 1). The current performance serves as a baseline against which future \nenhancements (e.g., ML -based predict ion, dynamic conservative thresholds) can be \nbenchmarked to achieve the target 20% latency reduction.  \nAlignment with Literature (Chapter 2): The findings resonate with the body of literature reviewed \nin Chapter 2: Literature Review.  \n\u25cf The detrimental impact of high RTT, startup delays, and stalling on QoE is well -\nestablished (e.g., works by Krishnan & Sitaraman, Dobrian et al.). This study provides \nfurther quantitative evidence in specific mobile contexts with an RTT -aware ABR.  \n\u25cf The trade -offs observed (e.g., lower bitrate for better stability for the high -RTT client) are \nconsistent with the fundamental challenges of ABR design (e.g., Yin et al. on control -\ntheoretic approaches, Akhshabi et al. on buffer -based decisions).  \n\u25cf The challenges in predicting mobile netw ork bandwidth and delay, and the impact of \nprediction errors on ABR performance, are also recognized themes. This study's use of \nsimple predictors highlights the need for more advanced techniques as suggested by \nresearch into ML for network prediction (e.g ., Mao et al., Balachandran et al., as cited in \nSection 2.3.4 and 3.3.2).  \n\u25cf The focus on RTT addresses a specific aspect of \"Network Delay versus Bandwidth \nFocus\" (Section 2.4.2) and \"Latency -Aware Adaptation Needs\" (Section 2.4.1) \nhighlighted as gaps.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 13,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": ".3.4 and 3.3.2).  \n\u25cf The focus on RTT addresses a specific aspect of \"Network Delay versus Bandwidth \nFocus\" (Section 2.4.2) and \"Latency -Aware Adaptation Needs\" (Section 2.4.1) \nhighlighted as gaps.\n\n[Page 18]\nAddressing Heterogeneity (Problem Statement & Section 2.4.3): While this set of simulations \nfocused on RTT heterogeneity, the framework inherently supports exploring other forms of \nheterogeneity (e.g., device processing power by adding a decoding delay, di fferent screen sizes \ninfluencing bitrate desirability). The current results emphasize that even with identical devices \nand ABRs, network path heterogeneity (specifically RTT) creates significant user experience \ndivergence.  \nLimitations of the Current Simula tion Study (Reiteration with Chapter Links): It is crucial to \ncontextualize these findings by acknowledging the study's limitations, many of which were \nanticipated in the design phase (Chapter 3):  \n1. RTT Profile Synthesis: While varied, the synthetic RTT prof iles may not capture all \nnuances of real -world RTT behavior and its correlation with other network parameters. \nFuture work could involve using real RTT traces if available.  \n2. Packet Loss Abstraction: Explicit packet loss and retransmission mechanisms are not  \nmodeled. Instead, their impact is implicitly captured in the reduced effective bandwidth of \nthe HSDPA traces. A more granular model could be a future extension, as packet loss is \na known issue in mobile networks (Section 2.2.1).  \n3. Player Model Simplificatio ns: The player model, while functional for ABR evaluation, \nomits certain complexities of commercial players. This is a common and accepted \nsimplification in ABR research to maintain tractability.  \n4. QoE Metric: The Simple QoE Score  is an objective proxy. Vali dating these findings \nwith subjective user studies (Section 3.4.2) would be essential for a complete QoE \nassessment.  \n5. Scope of Optimization: The current study focuses on client -side ABR. Coordinated \noptimizations involving server -side logic or network -level interventions (Section 2.3.1, \n2.3.2) were not simulated but represent important future directions.  \nImplications for Future Work and Optimization Strategies: The results strongly advocate for \ncontinued research into RTT -aware and predictive ABR algorithms.  Specific directions, aligning \nwith the goal of an optimized framework (Objective 3, Chapter 1), include:  \n\u25cf Advanced Prediction: Integrating Machine Learning models for more accurate short -term \nbandwidth and RTT forecasting (as discussed in Section 3.3.2).  \n\u25cf Dynamic ABR Parameters: Developing mechanisms for the LatencyAwareAbr  to \ndynamically adjust its internal parameters (e.g., \nLATENCY_AWARE_CONSERVATIVE_BUFFER_S , history window for prediction) based on \nthe perceived network state (RTT magnitude, RTT variance,  bandwidth stability).  \n\u25cf Stall-Anticipation and Recovery: Designing ABR logic that is more proactive in \nanticipating imminent stalls based on RTT trends and buffer trajectory, and more \naggressive in re -buffering strategies when RTT is high.  \n\u25cf Cross -Layer Infor mation: Exploring (theoretically, if not simulatable here) how \ninformation from lower network layers regarding RTT or congestion could be exposed to \nthe ABR for even more informed decisions.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 14,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "r Infor mation: Exploring (theoretically, if not simulatable here) how \ninformation from lower network layers regarding RTT or congestion could be exposed to \nthe ABR for even more informed decisions.\n\n[Page 19]\n4.9 Summary of Key Findings and Contributions  \nThis chapter has pr esented and meticulously analyzed the results from a series of simulations \ndesigned to investigate video streaming latency, particularly focusing on the impact of network \nRTT and the performance of an RTT -aware ABR algorithm. The key findings can be \nsummar ized as follows:  \n1. RTT as a Primary Performance Determinant: Network RTT exerts a profound and \nquantifiable influence on critical video streaming KPIs. Elevated RTT consistently \ntranslates to increased startup delays, compels ABR algorithms to select lower a verage \nbitrates to maintain stability, and is a major contributor to the playback latency \ndiscrepancy observed between users on different network paths.  \n2. Significant Viewer Discrepancy Quantified: The simulations successfully quantified the \nplayback time di fference between low -RTT and high -RTT clients. This discrepancy, \nrepresenting the \"delay between viewers,\" can range from a few seconds in relatively \nstable conditions to over 15 -20 seconds in highly challenging mobile network \nenvironments, severely impact ing synchronized or live viewing experiences.  \n3. Adaptive Behavior of LatencyAwareAbr : The custom -developed LatencyAwareAbr  \ndemonstrated its intended sensitivity to network RTT by making more conservative \nbitrate choices for clients experiencing higher delays . This behavior generally favored \nthe low -RTT client with superior quality and responsiveness.  \n4. Limitations and Trade -offs of Current RTT -Awareness: While beneficial, the current \nLatencyAwareAbr  could not fully overcome extreme network degradation. The stud y \nhighlighted inherent trade -offs, such as the high -RTT client sometimes achieving slightly \nbetter stall rates at the cost of significantly lower bitrates and still lagging in playback. \nThe simplicity of its predictive models and fixed conservative thresho lds represent areas \nfor future enhancement.  \n5. Validation of Mobile Network Challenges: The use of diverse, real -world mobile \nbandwidth traces (Bus, Metro -Tunnel, Train -Fast) confirmed the highly variable and \noften harsh conditions encountered in mobile strea ming, providing a rigorous testbed for \nABR algorithms.  \n6. Empirical Foundation for Optimization: These findings provide a strong empirical \nfoundation and clear direction for the subsequent phases of this research, particularly \nthe development of an optimized video delivery framework aimed at demonstrably \nreducing latency and viewer discrepancy, as per the project's overarching objectives \noutlined in Chapter 1.  \nContributions: This study contributes to the field by:  \n\u25cf Providing a focused, quantitative analysis of RTT's impact on viewer playback \ndiscrepancy using a controlled simulation environment with an RTT -aware ABR.  \n\u25cf Highlighting the limitations of current simple predictive mechanisms within ABRs when \nfaced with high  RTT and volatile bandwidth.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 15,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "sing a controlled simulation environment with an RTT -aware ABR.  \n\u25cf Highlighting the limitations of current simple predictive mechanisms within ABRs when \nfaced with high  RTT and volatile bandwidth.\n\n[Page 20]\n\u25cf Establishing a performance baseline for an RTT -aware ABR, against which more \nsophisticated latency optimization strategies can be benchmarked.  \n\u25cf Reinforcing the critical need for mobile -centric ABR designs that prioritize not only \nbandwidth adaptation but also robust RTT management and prediction.  \nThe insights gleaned from these results will directly inform the design and refinement of the \noptimize d video delivery framework proposed in this research.  \nReferences  \ni. Abadi, D. J., Carney, D., \u00c7etintemel, U., Cherniack, M., Convey, C., Lee, S., \u2026 Zdonik, \nS. (2003). Aurora: A new model and architecture for data stream management. VLDB \nJournal , 12(2), 120 \u2013139. \n \nii. Abadi, D. J., Ahmad, Y., Balazinska, M., \u00c7etintemel, U., Cherniack, M., Hwang, J. -H., \n\u2026 Zdonik, S. (2005). The design of the Borealis stream processing engine. Conference \non Innovative Data S ystems Research (CIDR) , 277 \u2013289. \n \niii. Ahmad, A., Floris, A., & Atzori, L. (2016). QoE -centric service delivery: A collaborative \napproach among OTTs and ISPs. Computer Networks , 110, 168 \u2013179. \nhttps ://doi.org/10.1016/j.comnet.2016.09.022  \n \niv. Akhshabi, S., Anantakrishnan, L., Dovrolis, C., & Begen, A. C. (2013). Server -based \ntraffic shaping for stabilizing oscillating adaptive streaming players. Proceedings of the \n23rd ACM Workshop on Network and Operati ng Systems Support for Digital Audio and \nVideo (NOSSDAV '13) , 19\u201324. \n \nv. Akhshabi, S., Begen, A. C., & Dovrolis, C. (2011). An experimental evaluation of rate -\nadaptation algorithms in adaptive streami ng over HTTP. Proceedings of the 2nd Annual \nACM Multimedia Systems Conference (MMSys '11) , 157 \u2013168. \n \nvi. Balachandran, A., Sekar, V., Akella, A., Seshan, S., Stoica, I., & Zhang, H. (2013). \nDeveloping a predictive model of quality of experience for Internet video. Proceedings of \nthe ACM SIGCOMM Conference , 339 \u2013350. https://doi.org/10.1145/2486001.2486028  \n \nvii. Balachandran, A., Sekar, V., Akella, A.,  Seshan, S., Stoica, I., & Zhang, H. (2013). \nDeveloping a predictive model of quality of experience for Internet video. Proceedings of \nthe ACM SIGCOMM Conference , 339 \u2013350. \n \nviii. Barth, D., Bellahsene, S., & Kloul, L. (2012). Mobility prediction using mobile use r \nprofiles. Proceedings of the IEEE Modeling and Analysis and Simulation of Computer",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 16,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "onference , 339 \u2013350. \n \nviii. Barth, D., Bellahsene, S., & Kloul, L. (2012). Mobility prediction using mobile use r \nprofiles. Proceedings of the IEEE Modeling and Analysis and Simulation of Computer\n\n[Page 21]\nand Telecommunication Systems (MASCOTS) , 333 -342. \n \nix. Barth, D., Bellahsene, S., & Kloul, L. (2012). Combining local and global profiles for \nmobility prediction in LTE femtoc ells. Proceedings of the ACM Modeling, Analysis and \nSimulation of Wireless and Mobile Systems (MSWiM) , 333 -342. \n \nx. Balachandran, A., Sekar, V., Akella, A., Seshan, S., Stoica, I., & Zhang, H. (2013). \nDeveloping a predictive model of quality of experience for  internet video. Proceedings of \nthe ACM SIGCOMM Conference , 339 \u2013350. \n \nxi. da Costa Filho, R. I. T., Lautenschlager, W., Kagami, N., Roesler, V., & Gaspary, L. P. \n(2016). Network fortune cookie: Using network measurements to predict video streaming \nperformance and QoE. 2016 IEEE Global Communications Conference (GLOBECOM) , \n1\u20136. https://doi.org/10.1109/GLOCOM.2016.7842022  \n \nxii. Dahlman, E., Mildh, G., Parkvall, S., Peisa, J., Sachs, J., Sel\u00e9n, Y., & Sk\u00f6ld, J. (2014). \n5G wireless access: Requirements and realization. IEEE Com munications Magazine , \n52(12), 42 \u201347. https://doi.org/10.1109/MCOM.2014.6979985  \n \nxiii. Dobrian, F., Sekar, V., Awan, A., Stoica, I., Chuang, D., Ganjam, A., ... Zhang, H. \n(2011). Understanding the impac t of video quality on user engagement. Proceedings of \nthe ACM SIGCOMM Conference (SIGCOMM '11) , 362 \u2013373. \nhttps://doi.org/10.1145/2018439.2018475  \n \nxiv. Fan, C. -L., Lee, J., Lo, W. -C., Huang, C. -Y., Chen,  K.-T., & Hsu, C. -H. (2017). Fixation \nprediction for 360 video streaming in head -mounted virtual reality. Proceedings of the \n27th Workshop on Network and Operating Systems Support for Digital Audio and Video \n(NOSSDAV '17) , 67\u201372. https://doi.org/10.1145/3083165.3083180  \n \nxv. Golrezaei, N., Molisch, A., Dimakis, A. G., & Caire, G. (2013). Femto -caching and \ndevice -to-device collaboration: A new architecture for wireless video distribution. IEEE \nCommunicati ons Magazine , 51(4), 142 \u2013149. \nhttps://doi.org/10.1109/MCOM.2013.6495741  \n \nxvi. Houdaille, R., & Gouache, S. (2012). Shaping HTTP adaptive streams for a better user \nexperience. Proceedings of the 3rd Mu ltimedia Systems Conference (MMSys '12) , 1\u20139. \nhttps://doi.org/10.1145/2155555.2155557  \n \nxvii. Jiang, J., Sekar, V., & Zhang, H. (2012). Improving fairness, efficiency, and stability in \nHTTP -based adaptive  video streaming with FESTIVE. Proceedings of the 8th ACM",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 17,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "145/2155555.2155557  \n \nxvii. Jiang, J., Sekar, V., & Zhang, H. (2012). Improving fairness, efficiency, and stability in \nHTTP -based adaptive  video streaming with FESTIVE. Proceedings of the 8th ACM\n\n[Page 22]\nInternational Conference on Emerging Networking Experiments and Technologies \n(CoNEXT '12) , 97\u2013108. http://dl.acm.org/citation.c fm?doid=2413176.2413189  \n \nxviii. Li, Z., Zhu, X., Gahm, J., Pan, R., Hu, Y., Begen, A. C., & Ye, J. (2014). Probe and \nadapt: Rate adaptation for HTTP video streaming at scale. IEEE Journal on Selected \nAreas in Communications , 32(4), 719 \u2013733. \n \nxix. Oyman, O., & Singh, S. (2012). Quality of experience for HTTP adaptive streaming \nservices. IEEE Communications Magazine , 50(4), 20 \u201327. \n \nxx. Paudyal, P., Battisti, F., & Carli, M. (n.d.). Impact of video content and transmission \nimpairments on quality of experience. Multimedia Tools and Applications . \n \nxxi. Petrangeli, S., Famaey, J., Claeys, M., Latr\u00e9, S., & De Turck, F. (2015). QoE -driven rate \nadaptation heuristic for fair adaptive video streaming. ACM Transactions on Multimedia \nComputing, Communications, and Applications , 12(2), Article 28.  \nhttps://doi.org/10.1145/2818361  \n \nxxii. Petrangeli, S., Swaminathan, V., Hosseini, M., & De Turck, F. (2017). An HTTP/2 -based \nadaptive streaming framework for 360 virtual reality videos. Proceedings of the 2017 \nACM on Multimedi a Conference (MM '17) , 306 \u2013314. \nhttps://doi.org/10.1145/3123266.3123453  \n \nxxiii. Qian, F., Ji, L., Han, B., & Gopalakrishnan, V. (2016). Optimizing 360 video delivery \nover cellular networks. Proceedings of  the 5th Workshop on All Things Cellular: \nOperations, Applications and Challenges (ATC '16) , 1\u20136. \nhttps://doi.org/10.1145/2980055.2980056  \n \nxxiv. Sodagar, I. (2011). The MPEG -DASH standard for multimedia streaming over the \nInternet. IEEE Multimedia , 18(4), 62 \u201367. \n \nxxv. Weng, J., et al., (2017). Evaluation of video streaming.  \n \nxxvi. Wu, C., Tan, Z., Wang, Z., & Yang, S. (2017). A dataset for exploring user behaviors in \nVR spherical video streaming. Proceedings of the 8th ACM on Multimedia Systems \nConference (MMSys '17) , 193 \u2013198. https://doi.org/10.1145/3083187.3083210  \n \nxxvii.  Yin, X., Jindal, A., Sekar, V., & Sinopoli, B. (2015). A control -theoretic approach for \ndynam ic adaptive video streaming over HTTP. SIGCOMM Computer Communication",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 18,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "0.1145/3083187.3083210  \n \nxxvii.  Yin, X., Jindal, A., Sekar, V., & Sinopoli, B. (2015). A control -theoretic approach for \ndynam ic adaptive video streaming over HTTP. SIGCOMM Computer Communication\n\n[Page 23]\nReview , 45(4), 325 \u2013338. https://doi.org/10.1145/2829988.2787486  \n \nxxviii.  Ominike A., Joshua J., Awodele O., Ogbonna A. (2020). Assessme nt of Quality of \nExperience (QoE) of Web and Video Services over a Mobile Network Using a Network \nEmulator. Journal of Computer and Communications . DOI:10.4236/jcc.2020.85005.  \n \nxxix. Palmer M., Appel M., Spiteri K., Chandrasekaran B., Feldmann A., Sitaraman R.K.  \n(2021). VOXEL: Cross -layer Optimization for Video Streaming with Imperfect \nTransmission. In Proc. of ACM CoNEXT 2021 . DOI:10.1145/3485983.3494864.  \n \nxxx. Sun L., Zong T., Wang S., Liu Y., Wang Y. (2021). Tightrope walking in low -latency live \nstreaming: Optimal joint adaptation of video rate and playback speed. In Proceedings of \nthe 12th ACM Multimedia Systems Conference (MMSys 2021) , pp. 201 \u2013213. \nDOI:10.1145/3458305.3463382.  \n \nxxxi. Huang T., Zhou C., Zhang R., Wu C., Sun L. (2023). Learning tailored adaptive bitrate \nalgorithms to heterogeneous network conditions: A domain -specific priors and meta -\nreinforcement learning approach. IEEE Journal on Selected Areas in Communications . \n(2023).  \n \nxxxii.  Li Y., Zhang X., Kang S., Cho J., Kim D., Qian Y., Ma S. (2023). Fleet: Improving q uality \nof experience for low -latency live video streaming. IEEE Transactions on Circuits and \nSystems for Video Technology . DOI:10.1109/TCSVT.2023.3243901.  \n \nxxxiii.  Wang B., Su M., Wang W., Chen K., Guo Z., Lin C., Xu Q., Guo S., Zhong L. (2024). \nEnhancing low late ncy adaptive live streaming through precise bandwidth prediction. \nIEEE/ACM Transactions on Networking . DOI:10.1109/TNET.2024.3426607.  \n \nxxxiv.  Woo J., Hong S., Kang D., An D. (2024). Improving the quality of experience of video \nstreaming through a buffer -based adaptive bitrate algorithm and gated recurrent unit -\nbased network bandwidth prediction. Applied Sciences . DOI:10.3390/app142210490.",
    "metadata": {
      "source_file": "documents/Chapter 4_ Results and Discussion - latency mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 19,
      "title": "Chapter 4_ Results and Discussion - latency mod(1)",
      "file_size": 1338813,
      "page_count": 23
    }
  },
  {
    "text": "[Page 1]\nChapter 3: Methodology  \nThis project employs a simulation -based, data -driven approach to comprehensively investigate \nand optimize video streaming latency, with a particular focus on client -side Adaptive Bitrate \n(ABR) strategies in mobile network environments. This approach combin es the utilization of \nreal-world mobile network bandwidth data with controlled experimental setups executed within a \ncustom -developed simulation environment. This methodology facilitates the development and \nrigorous evaluation of a novel ABR algorithm desi gned to be sensitive to network delay. The \nmultifaceted nature of this approach is essential due to the complexity of video streaming \nlatency, which is influenced by multiple interacting factors. It allows for robust validation of \nproposed algorithmic solu tions through the systematic collection and analysis of quantitative \nperformance data, with the simulation environment enabling controlled manipulation of key \nnetwork variables like Round -Trip Time (RTT) while leveraging the ecological validity of \nempirica l bandwidth traces.  \n3.1 Phases of the Research  \nThe research is structured into three principal phases, ensuring a logical progression from \nunderstanding the problem space to developing and evaluating solutions:  \n3.1.1 Data Acquisition and Environment Setup  \nThis initial phase focuses on acquiring the necessary input data and establishing the simulation \nenvironment.  \n1. Bandwidth Trace Acquisition:  Real-world mobile network bandwidth traces (e.g., \nHSDPA traces from the UMass SIGCOMM'09 and MMSys'13 repositories) a re collected. \nThese traces provide time -series data of achieved throughput, reflecting the dynamic \ncapacity of mobile networks under various conditions (e.g., urban bus routes, metro \ntunnels, train lines).  \n2. RTT Profile Definition:  Synthetic Round -Trip Time (RTT) profiles are defined to \nrepresent diverse network path delay characteristics. These profiles include parameters \nfor base RTT and percentage of fluctuation, allowing for the simulation of clients with \nvarying network responsiveness (e.g., 'LowLatency'  vs. 'HighLatency' profiles).  \n3. Simulation Environment Development:  A custom simulation environment is \nimplemented in Python. This environment includes:  \ni. A model of a segmented video stream with multiple selectable bitrate levels.  \nii. A simulated video player cap able of requesting segments, managing a playback \nbuffer, and implementing ABR logic.  \niii. The ability to process input bandwidth traces and apply synthetic RTT profiles to \nsegment download calculations.",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 0,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "f requesting segments, managing a playback \nbuffer, and implementing ABR logic.  \niii. The ability to process input bandwidth traces and apply synthetic RTT profiles to \nsegment download calculations.\n\n[Page 2]\niv. Comprehensive logging capabilities for network conditions,  player states, ABR \ndecisions, and key performance metrics.  \n3.1.2 Algorithm Development and Implementation  \nThis phase concentrates on the design and implementation of the primary ABR algorithm under \ninvestigation:  \n1. LatencyAwareAbr  Development:  A novel ABR a lgorithm, termed \nLatencyAwareAbr , is developed. Its core design principle is the explicit consideration \nof network delay (RTT) in conjunction with predicted bandwidth and buffer status to \nmake bitrate adaptation decisions.  \n2. Predictive Heuristics:  The LatencyAwareAbr  incorporates predictive techniques to \nestimate future network conditions. Specifically, it utilizes a harmonic mean of recent \nbandwidth measurements for short -term throughput forecasting and a moving average of \nrecent RTT measurements for delay f orecasting, operating over a defined historical \nwindow.  \n3. Conservative Adaptation Logic:  The algorithm includes logic for conservative \nupshifting, such as requiring the player buffer to exceed a specific threshold \n(LATENCY_AWARE_CONSERVATIVE_BUFFER_S ) before  considering an increase in \nvideo quality, aiming to balance quality maximization with playback stability.  \n4. Implementation:  The LatencyAwareAbr  is implemented as a modular component \nwithin the Python simulation environment, allowing for its evaluation and c omparison. (A \nbaseline algorithm, such as a simple buffer -based ABR, may also be implemented for \ncomparative benchmarking).  \n3.1.3 Simulation, Evaluation, and Analysis  \nThis phase involves executing the simulations and analyzing the generated data:  \n1. Simulation Execution:  A series of simulation experiments are conducted. Each \nexperiment typically involves:  \ni. Selecting a specific bandwidth trace.  \nii. Assigning defined RTT profiles to one or more simulated clients.  \niii. Running the simulation with the chosen ABR al gorithm(s) (e.g., \nLatencyAwareAbr ). \n2. Data Logging:  During each simulation run, detailed time -series data is logged, including \ninstantaneous bandwidth, applied RTT, player buffer level, selected bitrate, player state \n(initializing, buffering, playing, stalled), and cumulative playback time.  \n3. Performance Met ric Calculation:  Upon completion of each simulation, a suite of Key \nPerformance Indicators (KPIs) is calculated from the logged data. These include startup \ndelay, total stall time, buffering ratio, average selected bitrate, number of quality \nswitches, and a composite QoE score. A critical derived metric is the playback latency \ndiscrepancy  between concurrently simulated clients.",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 1,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "ffering ratio, average selected bitrate, number of quality \nswitches, and a composite QoE score. A critical derived metric is the playback latency \ndiscrepancy  between concurrently simulated clients.\n\n[Page 3]\n4. Results Analysis and Discussion:  The collected KPIs and time -series data are \nanalyzed to:  \ni. Quantify the impact of RTT on individual client performance and on the playback \ndiscrepancy between clients.  \nii. Evaluate the effectiveness of the LatencyAwareAbr  in managing latency and \nQoE under diverse conditions.  \niii. Identify strengths, weaknesses, and areas for refinement in the ABR algorithm.  \niv. Draw conclusions regarding optimal strategies for latency reduction in mobile \nvideo streaming. Visualization of time -series data and statistical summaries of \nKPIs are key components of this analysis.  \n3.2 Simulation Environment and Data Sources  \nThe core of this research methodology relies on a custom -developed simulation environment \ndesigned to model the adaptive video streaming process under controlled yet realistic network \nconditions.  \n3.2.1 Simulation Framework  \nThe simulation framework, implemented in Python, p rovides the controlled experimental setup. \nKey components include:  \n1. Video Source Model:  Represents a video asset pre -segmented into fixed -duration \nchunks (e.g., 2 seconds), each available at multiple predefined bitrate levels (e.g., \n300kbps to 6000kbps).  \n2. Simulated Player Model:  This component emulates the client -side video player. It is \nresponsible for:  \ni. Requesting video segments one by one.  \nii. Implementing the ABR logic (e.g., LatencyAwareAbr ) to select the appropriate \nbitrate for the next segment based on its perception of network conditions and \nbuffer state.  \niii. Managing a virtual playback buffer with defined minimum (for startup) and \nmaximum capacities.  \niv. Simulating video playback by depleting the buffer at the playback rate of the \ncurrently playing segment.  \nv. Tracki ng its internal state (initializing, buffering, playing, stalled) and various \nperformance metrics.  \n3. Network Model:  This component interfaces the player with the video source and applies \nnetwork conditions:  \ni. Bandwidth Input:  Reads time -series bandwidth data from real -world mobile \nnetwork traces (detailed in 3.2.2). The simulation progresses in discrete time \nsteps, and the available bandwidth for segment downloads is determined by the \ntrace value at the current simulation time .",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 2,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "work traces (detailed in 3.2.2). The simulation progresses in discrete time \nsteps, and the available bandwidth for segment downloads is determined by the \ntrace value at the current simulation time .\n\n[Page 4]\nii. RTT/Delay Application:  Applies a synthetically generated RTT to each segment \ndownload. The RTT for a given client can be configured with a base value and a \nfluctuation model, allowing for the simulation of different network path delay \ncharacteristics. Th e segment download time is calculated as: \nTransmissionTime (SegmentSize / Bandwidth) + RTT . \n4. Logging and Metrics Module:  Records all relevant parameters and events throughout \nthe simulation (e.g., chosen bitrates, buffer levels, stalls, playback time) for p ost-\nsimulation analysis and KPI calculation.  \n3.2.2 Data Sources for Simulation Input  \nTwo primary types of data feed into the simulation:  \n1. Real -World Mobile Bandwidth Traces:  \ni. Source:  Publicly available datasets of HSDPA mobile network bandwidth \nmeasurements,  such as those provided by UMass for the SIGCOMM'09 and \nMMSys'13 conferences (Mao et al., 2017; Akhshabi et al., 2011). These traces \nwere collected during real -world mobile usage scenarios (e.g., on buses, trains, \nmetro systems).  \nii. Format:  Typically, these t races provide timestamped entries indicating the \namount of data transferred over a short measurement interval. This data is \nprocessed by the simulator to create a time -series of available bandwidth (kbps).  \niii. Significance:  Using these traces injects realistic bandwidth variability and \ncharacteristics of mobile networks (e.g., fluctuations, handovers, periods of low \nconnectivity) into the simulation, enhancing the ecological validity of the ABR \nperformance evaluation.  \n2. Synthe tic Round -Trip Time (RTT) Profiles:  \ni. Generation:  RTT profiles are generated synthetically within the simulation \nenvironment. This allows for precise control over the delay characteristics \nexperienced by simulated clients.  \nii. Parameters:  Each profile is typical ly defined by a base_delay_ms , a \ndelay_pattern  (e.g., 'fluctuating', 'stable'), a \ndelay_fluctuation_percent , and a delay_change_interval_s_base . \nThis enables the creation of distinct client network path conditions, such as a \nlow-RTT client versus a high -RTT client.  \niii. Significance:  Synthetic RTT generation permits the systematic investigation of \nRTT's isolated impact on streaming performance and ABR behavior, a key focus \nof this research. It allows for controlled comparisons between clients differing \nonly in t heir RTT characteristics while experiencing the same bandwidth \nconditions.  \nBy combining real bandwidth traces with controlled synthetic RTT profiles, the simulation aims \nto strike a balance between realism and experimental control, providing a robust platf orm for \nanalyzing latency optimization strategies.",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 3,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "with controlled synthetic RTT profiles, the simulation aims \nto strike a balance between realism and experimental control, providing a robust platf orm for \nanalyzing latency optimization strategies.\n\n[Page 5]\n3.3 Algorithm Under Investigation: LatencyAwareAbr  \nThe primary algorithm developed and evaluated in this research is LatencyAwareAbr . This \nsection details its objectives, core logic, and implementation asp ects within the simulation \nframework.  \n3.3.1 Algorithm Objectives  \nThe LatencyAwareAbr  is designed with the following primary objectives, reflecting the overall \ngoals of this research:  \n1. Minimize Perceived Latency:  This includes reducing startup delay, minimiz ing the \nfrequency and duration of stall events (rebuffering), and lessening the playback \nprogression lag relative to other viewers or an ideal timeline.  \n2. Optimize Buffer Management:  To maintain a stable buffer that acts as a cushion \nagainst network variabil ity, preventing depletion while also avoiding excessive buffering \nthat could contribute to initial or interactive latency.  \n3. Maintain Acceptable Video Quality:  While prioritizing latency, the algorithm also aims \nto deliver the highest possible video quality (bitrate) that can be sustained under the \nprevailing network conditions and latency constraints, thereby contributing positively to \nthe overall Quality of Ex perience (QoE).  \n4. Adapt to Network Dynamics:  To effectively respond to fluctuations in both available \nbandwidth and network RTT, common in mobile environments.  \n3.3.2 Core Adaptation Logic of LatencyAwareAbr  \nThe LatencyAwareAbr  makes segment -by-segment bitrate selection decisions based on an \namalgamation of factors:  \n1. Bandwidth Prediction:  \ni. It maintains a history of recently observed segment download throughputs.  \nii. The predicted throughput for the next segment is calculated using a harmonic \nmean  of the throughputs in a defined recent history window \n(history_window_s ). The harmonic mean is chosen for its tendency to be \ninfluenced more by lower values, offering a somewhat conservative estimate in \nvariable conditions.  \n2. RTT/Delay Predictio n: \ni. It maintains a history of recently measured RTTs (derived from the synthetic RTT \nprofile applied to the client).  \nii. The predicted RTT for the next segment download is calculated using a moving \naverage  of the RTTs in a defined recent history window.  \n3. Estimat ed Segment Download Time:",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 4,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "lied to the client).  \nii. The predicted RTT for the next segment download is calculated using a moving \naverage  of the RTTs in a defined recent history window.  \n3. Estimat ed Segment Download Time:\n\n[Page 6]\ni. For each available bitrate quality, the algorithm estimates the time required to \ndownload the next segment. This is calculated as: EstimatedDownloadTime \n= (SegmentSizeInBits / PredictedThroughputInBps) + \nPredictedRTTInSeconds  \nii. A safety factor ( DOWNLOAD_TIME_SAFETY_FACTOR ) is applied to this estimate \nto account for prediction inaccuracies and sudden network changes.  \n4. Buffer -Aware and Latency -Sensitive Decision Making:  \ni. The algorithm iterates through available bitrates, typically from h ighest to lowest.  \nii. It selects the highest quality for which the \nsafe_estimated_download_time_s  is less than the segment duration \n(ensuring, ideally, that the segment can be downloaded faster than it is played).  \niii. Conservative Upshifting:  A specific buffer thr eshold \n(LATENCY_AWARE_CONSERVATIVE_BUFFER_S ) is used. If the current buffer \nlevel is below this threshold, the algorithm is more reluctant to switch to a higher \nbitrate, even if throughput predictions are favorable. It might only upshift if the \nestimated d ownload time for the higher quality is significantly (e.g., >30%) faster \nthan the segment duration, or it might maintain the current or a lower quality. This \naims to prevent overly optimistic upshifts that could quickly deplete a fragile \nbuffer, especially  when RTT is high or variable.  \niv. Downshifting:  If no quality can be downloaded within the segment duration or if \nbuffer levels are critically low, the algorithm will aggressively downshift, \npotentially to the lowest available bitrate, to prioritize avoiding or recovering from \na stall.  \n3.3.3 Implementation in the Simulation Environment  \nThe LatencyAwareAbr  is implemented as a Python class within the simulation framework. \nThis class encapsulates the state (e.g., history of bandwidth/RTT, current quality index) a nd the \nlogic described above. It receives the current player state (buffer level, network observations) \nfrom the simulator at each decision point (before requesting a new segment) and returns the \nchosen quality index for the next segment. This modular desi gn allows for easy substitution with \nother ABR algorithms for comparative studies.  \n3.4 Evaluation Methodology and Metrics  \nThe performance of the LatencyAwareAbr  algorithm, particularly its effectiveness in \nmanaging latency under varying RTT conditions, is assessed using a quantitative evaluation \nmethodology within the developed simulation framework.  \n3.4.1 Experimental Design for Evaluation",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 5,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "veness in \nmanaging latency under varying RTT conditions, is assessed using a quantitative evaluation \nmethodology within the developed simulation framework.  \n3.4.1 Experimental Design for Evaluation\n\n[Page 7]\nThe core experimental design focuses on comparing the performance of simulated clients \noperating under different RTT profiles while sharing the same challenging mobile bandwidth \ntrace.  \n1. Controlled Variable:  The primary independent variable manipulated is th e client's RTT \nprofile (e.g., Client1_LowLatency  vs. Client2_HighLatency ). \n2. Constant Factors:  For these direct comparisons, the input bandwidth trace and the \nABR algorithm ( LatencyAwareAbr ) are kept identical for all clients in a given \nsimulation run. Player parameters (e.g., buffer sizes, segment duration) are also \nconstant.  \n3. Benchmarking (Optional):  For a broader evaluation of LatencyAwareAbr  itself, its \nperformance can be benchmarked agai nst a baseline ABR (e.g., a simple buffer -based \nABR) under identical network trace and RTT conditions.  \nSimulations are run for the full duration of each selected bandwidth trace. Multiple traces \nrepresenting different mobile scenarios (Bus, Metro -Tunnel, T rain-Fast) are used to assess \nperformance across a range of network dynamics.  \n3.4.2 Objective Performance Metrics  \nThe following objective metrics, automatically logged and calculated by the simulation \nframework, are used to quantify performance. These alig n with common industry and academic \nmeasures of streaming QoE:  \n1. Startup Delay (seconds):  The time elapsed from the simulation start (representing user \nrequest) until the player buffer reaches MIN_BUFFER_TO_START_S  and playback \ncommences.  \n2. Total Stall Time (s econds):  The cumulative duration the player spends in a 'STALLED' \nstate due to buffer underrun after playback has started.  \n3. Buffering Ratio (%):  The Total Stall Time expressed as a percentage of the total \nplayback session duration (playback time + stall tim e). \n4. Average Selected Bitrate (kbps):  The mean bitrate of all video segments successfully \ndownloaded and played during the session, weighted by their duration. This serves as a \nproxy for perceived video quality.  \n5. Quality Switch Frequency (count / switches pe r minute):  The total number of times \nthe ABR algorithm changes the video quality level during playback. This can also be \nnormalized by playback duration.  \n6. Playback Latency Discrepancy (seconds):  Calculated at each simulation time step as \nthe difference in current_playback_time_s  between two concurrently simulated \nclients (e.g., PlaybackTime_Client1 - PlaybackTime_Client2 ). This directly \nmeasures the relative lag or lead between viewers. Time -series plots and summary \nstatistics (e.g., average and maximum disc repancy) are analyzed.  \n7. Simple QoE Score:  A composite objective metric calculated as: QoE = \n(AverageBitrateReward) - (StartupPenalty) -",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 6,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "ts and summary \nstatistics (e.g., average and maximum disc repancy) are analyzed.  \n7. Simple QoE Score:  A composite objective metric calculated as: QoE = \n(AverageBitrateReward) - (StartupPenalty) -\n\n[Page 8]\n(BufferingRatioPenalty) - (SwitchPenalty)  where rewards and penalties \nare weighted factors. This provides a single figure  of merit for overall experience, though \nits specific formulation must be acknowledged.  \n3.4.3 Data Analysis and Interpretation  \nThe analysis involves:  \n1. Descriptive Statistics:  Calculating mean, median, and variance for the above KPIs \nacross different simulat ion runs (e.g., per trace, per RTT profile).  \n2. Time -Series Visualization:  Plotting key metrics over simulation time (e.g., buffer level, \nselected bitrate, RTT, bandwidth, playback latency discrepancy) to understand the \ndynamic behavior of the ABR and player.  \n3. Comparative Analysis:  Comparing KPIs and dynamic behaviors between clients with \ndifferent RTT profiles or between different ABR algorithms.  \n4. Correlation Analysis (Potential):  Exploring correlations between input network \nparameters (e.g., RTT magnitude, RTT  variance, bandwidth volatility) and output \nperformance metrics.  \nThe results are interpreted in the context of the research objectives, focusing on how RTT \nimpacts latency and how effectively the LatencyAwareAbr  mitigates these impacts. Insights \ngained are  used to identify strengths and weaknesses of the algorithm and to inform potential \nrefinements. While this phase relies on objective data, the implications for subjective user \nexperience are discussed based on established relationships between objective m etrics and \nperceived QoE from the literature.  \nReferences  \n1. Akhshabi, S., Anantakrishnan, L., Dovrolis, C., & Begen, A. C. (2013). Server -based \ntraffic shaping for stabilizing oscillating adaptive streaming players. Proceedings of the \n23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and \nVideo (NOSSDAV '13) , 19\u201324. \n2. Akhshabi, S., Begen, A. C., & Dovrolis, C. (2011). An experimental evaluation of rate -\nadaptation algorithms in adaptive streamin g over HTTP. Proceedings of the 2nd Annual \nACM Multimedia Systems Conference (MMSys '11) , 157\u2013168. \n3. Balachandran, A., Sekar, V., Akella, A., Seshan, S., Stoica, I., & Zhang, H. (2013). \nDeveloping a predictive model of quality of experience for Internet vide o. Proceedings of \nthe ACM SIGCOMM Conference , 339\u2013350. \n4. da Costa Filho, R. I. T., Lautenschlager, W., Kagami, N., Roesler, V., & Gaspary, L. P. \n(2016). Network fortune cookie: Using network measurements to predict video streaming \nperformance and QoE. 2016 IEEE Global Communications Conference (GLOBECOM) , \n1\u20136.",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 7,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "Roesler, V., & Gaspary, L. P. \n(2016). Network fortune cookie: Using network measurements to predict video streaming \nperformance and QoE. 2016 IEEE Global Communications Conference (GLOBECOM) , \n1\u20136.\n\n[Page 9]\n5. Dahlman, E., Mildh, G., Parkvall, S., Peisa, J., Sachs, J., Sel\u00e9n, Y., & Sk\u00f6ld, J. (2014). \n5G wireless access: Requirements and realization. IEEE Communications Magazine , \n52(12), 42\u201347. \n6. Fan, C. -L., Lee, J., Lo, W. -C., Huang, C. -Y., Chen, K. -T., & Hsu, C. -H. (2017). Fixation \nprediction for 360 video streaming in head -mounted virtual reality. Proceedings of the \n27th Workshop on Network and Operating Systems Support for Digital Audio and Video \n(NOSSDA V '17) , 67\u201372. \n7. Houdaille, R., & Gouache, S. (2012). Shaping HTTP adaptive streams for a better user \nexperience. Proceedings of the 3rd Multimedia Systems Conference (MMSys '12) , 1\u20139. \n8. Mao, H., Netravali, R., & Alizadeh, M. (2017). Neural adaptive video stre aming with \npensieve. Proceedings of the Conference of the ACM Special Interest Group on Data \nCommunication (SIGCOMM '17) , 197 -210. \n9. Oyman, O., & Singh, S. (2012). Quality of experience for HTTP adaptive streaming \nservices. IEEE Communications Magazine , 50(4), 20\u201327. \n10. Paudyal, P., Battisti, F., & Carli, M. (n.d.). Impact of video content and transmission \nimpairments on quality of experience. Multimedia Tools and Applications . \n11. Petrangeli, S., Famaey, J., Claeys, M., Latr\u00e9, S., & De Turck, F. (2015). QoE -driven rate \nadaptation heuristic for fair adaptive video streaming. ACM Transactions on Multimedia \nComputing, Communications, and Applications , 12(2), Article 28.  \n12. Petrangeli, S., Swaminathan, V., Hosseini, M., & De Turck, F. (2017). An HTTP/2 -based \nadaptive strea ming framework for 360 virtual reality videos. Proceedings of the 2017 \nACM on Multimedia Conference (MM '17) , 306\u2013314. \n13. Smith, J., Doe, A., & Brown, B. (2020). Scalable Cloud Architectures for Video \nStreaming. Journal of Cloud Computing , 9(1), 1 -15. (Exampl e placeholder for a cloud \ndeployment reference if relevant to future scope discussed) . \n14. Weng, J., et al., (2017). Evaluation of video streaming. (This is too vague, needs a full \ncitation or replacement if a specific paper is intended) . \n15. Wu, C., Tan, Z., Wang , Z., & Yang, S. (2017). A dataset for exploring user behaviors in \nVR spherical video streaming. Proceedings of the 8th ACM on Multimedia Systems \nConference (MMSys '17) , 193\u2013198. \n16. Yin, X., Jindal, A., Sekar, V., & Sinopoli, B. (2015). A control -theoretic ap proach for \ndynamic adaptive video streaming over HTTP. SIGCOMM Computer Communication \nReview , 45(4), 325\u2013338.",
    "metadata": {
      "source_file": "documents/Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 8,
      "title": "Chapter 3_ Methodology - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 188203,
      "page_count": 9
    }
  },
  {
    "text": "[Page 1]\nAbstract  \nMobile video streaming constitutes a significant and rapidly growing portion of internet traffic, yet \ndelivering a consistently high Quality of Experience (QoE) remains challenging due to the \ninherent variability of mobile networks. Latency, in its various  manifestations including startup \ndelays, buffering events, and particularly the playback progression discrepancy between \nconcurrent viewers, severely impacts user satisfaction. While much research has focused on \nbandwidth adaptation, the distinct and crit ical role of network Round -Trip Time (RTT) as a \nprimary contributor to these latency issues is often underexplored.  \nThis research presents a comprehensive investigation into the impact of RTT on adaptive video \nstreaming latency and proposes client -side Ada ptive Bitrate (ABR) strategies to mitigate these \neffects. A simulation framework was developed, driven by real -world mobile HSDPA bandwidth \ntraces and utilizing synthetically generated, controlled RTT profiles to emulate diverse network \npath delays for mul tiple concurrent clients. The performance of a novel RTT -aware ABR \nalgorithm, LatencyAwareAbr , was evaluated against these conditions, focusing on its ability to \nmanage playback latency and viewer discrepancy.  \nThe empirical results demonstrate that increas ed RTT significantly degrades streaming \nperformance, leading to longer startup times (average increase of 0.23s for high -RTT client), \nlower average selected bitrates (approximately 20% reduction for high -RTT client), and \nsubstantial playback latency discre pancies between users, which can exceed 18 seconds in \nchallenging network scenarios. The LatencyAwareAbr  algorithm showed adaptive behavior \nby making more conservative bitrate choices for higher -RTT clients, partially mitigating stalls in \nsome conditions b ut still resulting in noticeable playback lag and reduced overall QoE compared \nto low -RTT clients. The findings quantify the trade -offs involved and highlight the limitations of \nsimple predictive heuristics within ABRs when faced with high RTT and volatile  bandwidth.  \nThis study contributes by providing a focused, quantitative analysis of RTT's impact on viewer \nplayback discrepancy, establishing a performance baseline for an RTT -aware ABR, and \nunderscoring the critical need for mobile -centric ABR designs tha t robustly incorporate RTT \nmanagement and advanced predictive capabilities. The insights derived inform the development \nof more sophisticated latency optimization techniques crucial for enhancing user experience in \nthe evolving mobile video streaming lands cape, particularly for latency -sensitive live and \ninteractive applications.  \nChapter 1: Analyzing and Optimizing \nLatency in Video Streaming",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 0,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "experience in \nthe evolving mobile video streaming lands cape, particularly for latency -sensitive live and \ninteractive applications.  \nChapter 1: Analyzing and Optimizing \nLatency in Video Streaming\n\n[Page 2]\n1.1 Background of the Study  \nVideo streaming has become a cornerstone of modern digital communication and \nentertainmen t. Its pervasive presence spans various applications, from on -demand content \nplatforms like Netflix and YouTube to real -time services such as video conferencing and \ninteractive gaming. The escalating demand for high -quality video streaming, particularly on  \nmobile devices, necessitates continuous innovation to address the inherent challenges of \ndelivering seamless and low -latency experiences.  \nThe proliferation of mobile devices and the exponential growth of mobile video traffic have \ntransformed the landscape  of content consumption. This surge in demand underscores the \ncritical need for efficient video delivery mechanisms that can cope with the constraints of mobile \nnetworks. However, mobile networks are inherently variable, characterized by fluctuating \nbandwi dth, variable Round -Trip Times (RTTs), and signal strength, posing significant obstacles \nto achieving consistent QoE (Oyman & Singh, 2012).  \nLatency, the delay between content creation and playback, emerges as a key bottleneck in \ndelivering satisfactory vid eo streaming experiences. This includes not only client -side perceived \nlatency like startup delay and stalling, but also, critically for live or co -viewing scenarios, the \ndiscrepancy in playback progression between different users due to varying network co nditions. \nEven minor delays can significantly degrade QoE, leading to user frustration, reduced \nengagement, and potential revenue loss for content providers (Balachandran et al., 2013; \nDobrian et al., 2011). Studies have revealed that a substantial portion  of online video viewers \nencounter buffering, startup delays, and low resolution \u2014all manifestations of latency \u2014\nhighlighting the urgent need for effective latency optimization strategies (Dobrian et al., 2011).  \nAdaptive HTTP streaming technologies, such as MPEG -DASH, HLS, and Smooth Streaming, \nhave emerged as industry standards to address the challenges of video streaming over variable \nnetworks (Sodagar, 2011). These protocols employ techniques like adaptive bitrate selection, \nsegmented delivery, and client -side buffering to mitigate the impact of network fluctuations and \noptimize QoE. This study will investigate these dynamics within a simulated Adaptive Bitrate \n(ABR) streaming environment, allowing for controlled manipulation of factors like RTT to \nevaluate  novel client -side ABR logic. However, existing adaptive streaming protocols often \nprioritize high bitrates and video quality over minimizing latency, particularly in mobile \nenvironments (Yin et al., 2015). This prioritization can lead to suboptimal QoE in  delay -sensitive \napplications and scenarios characterized by fluctuating bandwidth and high network delays \n(Petrangeli et al., 2017). Furthermore, research in video streaming optimization has \npredominantly focused on bandwidth as the primary limiting facto r, often overlooking the critical \nrole of network delay, specifically RTT, as a major contributor to latency (Oyman & Singh, \n2012). While bandwidth is undoubtedly important, network delay directly impacts interactivity, \nresponsiveness, and the efficiency o f ABR decision -making, especially in real -time applications \n(Balachandran et al., 2013). In mobile environments, network delay can be particularly \npronounced and unpredictable, further exacerbating latency issues and hindering QoE (da \nCosta Filho et al., 2 016).",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 1,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "achandran et al., 2013). In mobile environments, network delay can be particularly \npronounced and unpredictable, further exacerbating latency issues and hindering QoE (da \nCosta Filho et al., 2 016).\n\n[Page 3]\n1.2 Statement of the Problem  \nThe central problem this project addresses is the persistent challenge of high latency and \nplayback discrepancies in adaptive video streaming, especially within the context of mobile \nnetworks. Despite significant advancem ents in video streaming technologies and protocols, \nlatency remains a major impediment to delivering truly seamless and high -quality user \nexperiences. Specifically, the problem statement can be articulated as follows:  \nHigh latency (including significant ne twork RTT) in adaptive video streaming, particularly in \nmobile network environments, continues to degrade Quality of Experience (QoE) for end -users \nby increasing startup times, causing stalls, forcing suboptimal bitrate choices, and leading to \nsignificant playback progression discrepancies between concurrent viewers, hindering user \nengagement, and impacting the viability of video streaming services.  \nThis overarching problem encompasses several specific issues:  \n1. Suboptimal QoE in Mobile Networks:  Current adap tive streaming protocols often fail \nto deliver optimal QoE in mobile networks due to their tendency to prioritize high bitrates \nover low latency. This is particularly problematic in mobile environments characterized \nby fluctuating bandwidth and high networ k delays, where latency (including RTT) \nbecomes a dominant factor in user perception. Existing protocols like DASH and HLS, \nwhile effective in adapting to varying bandwidth conditions, may not adequately address \nthe latency -sensitive nature of real -time ap plications and user expectations in mobile \nscenarios (Petrangeli et al., 2017). Simulations in this research will specifically \ndemonstrate this, particularly for clients experiencing higher RTTs.  \n \n2. Insufficient Focus on Network Delay (RTT):  Existing researc h and optimization efforts \nin video streaming often prioritize bandwidth optimization, neglecting the crucial role of \nnetwork delay (specifically RTT) as a primary latency contributor. This bandwidth -centric \napproach overlooks the fact that network delay, even with ample bandwidth, can \nsignificantly impact latency and QoE, especially in mobile environments where delay is \noften unpredictable and highly variable. This research directly addresses this by \nmodeling and varying RTT in a controlled simulation envi ronment to quantify its specific \nimpact on ABR performance and viewer discrepancy, distinct from bandwidth. The \ncustom LatencyAwareAbr  evaluated herein attempts to factor in RTT. The complex \ninterplay between bandwidth and delay and their combined impact o n user experience \nrequire further investigation and tailored optimization strategies (Oyman & Singh, 2012).  \n \n3. Lack of Adaptation to Heterogeneity (Specifically Network Path RTT):  The \nincreasing heterogeneity of mobile devices and network conditions presents  a significant \nchallenge for latency optimization. While various forms of heterogeneity exist, this \nstudy's initial empirical work focuses on quantifying the impact of network path RTT \nheterogeneity between clients using the same ABR logic. Existing algori thms often \nassume homogeneous environments and fail to account for the diverse network",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 2,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "ntifying the impact of network path RTT \nheterogeneity between clients using the same ABR logic. Existing algori thms often \nassume homogeneous environments and fail to account for the diverse network\n\n[Page 4]\ncharacteristics of real -world mobile devices and networks. This lack of adaptability \nresults in suboptimal performance and QoE for a significant portion of users, partic ularly \nthose operating in challenging network conditions with high RTT. Optimization strategies \nmust be tailored to address the unique characteristics of individual devices and network \nenvironments to ensure consistent and high -quality QoE across diverse u ser populations \n(Petrangeli et al., 2015).  \n \n4. Fundamental Latency Challenges for Live and Immersive Applications:  The advent \nof VR and 360 -degree video streaming introduces new and amplified latency challenges. \nThese immersive experiences demand ultra -low la tency to avoid motion sickness and \nensure a sense of presence and realism (Akhshabi et al., 2013). While specific viewport \nprediction and tile -based streaming techniques (Fan et al., 2017) are promising for \nbandwidth optimization in VR, the fundamental iss ues of RTT impact on ABR \nresponsiveness and playback discrepancy are critical for all streaming, and \nunderstanding them is a prerequisite for tackling more complex scenarios. The current \nimplemented work focuses on these foundational aspects rather than VR -specific ABR \noptimizations.  \n \n1.3 Aim and Objectives  \nAim:  \nThe overarching aim of this project is to significantly reduce latency and playback discrepancy in \nadaptive video streaming, particularly in mobile networks, to enhance Quality of Experience \n(QoE) f or end -users and improve the overall performance and efficiency of video streaming \nservices.  \nObjectives:  \nTo achieve this aim, the project will pursue the following specific objectives:  \n1. Analyze and quantify latency factors in client -side adaptive video streaming:  This \nobjective involves a comprehensive investigation through simulation of the various \nfactors that contribute to latency in video streaming, including network conditions (real -\nworld bandwidth traces and controlled round -trip time profiles), and client -side factors \n(ABR algorithm logic, buffer management strategies). The analysis will focus on \nunderstanding the relative importance of each factor and their interplay in determining  \noverall latency and QoE, with a key aspect being the quantification of playback latency \ndiscrepancy between users experiencing different RTTs.  \n \n2. Evaluate the impact of different client -side adaptive bitrate (ABR) strategies on \nlatency and QoE:  This objecti ve aims to assess the latency performance of ABR \nstrategies, particularly a novel LatencyAwareAbr  designed to be RTT -sensitive, under",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 3,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "ive bitrate (ABR) strategies on \nlatency and QoE:  This objecti ve aims to assess the latency performance of ABR \nstrategies, particularly a novel LatencyAwareAbr  designed to be RTT -sensitive, under\n\n[Page 5]\nvarying mobile network conditions (bandwidth and RTT). The evaluation will identify the \nstrengths and weaknesses of these ABR approaches in terms of latency optimization \nand inform the development of more effective solutions.  \n \n3. Propose and evaluate an optimized ABR strategy that reduces latency by at least \n20% in key metrics:  This objective focuses on the design and implementa tion (within \nthe simulation environment) of a novel or enhanced ABR strategy that incorporates \nadvanced latency optimization techniques, informed by the findings from Objectives 1 \nand 2. The target latency reduction of at least 20% in metrics such as start up delay, \nbuffering ratio, or playback latency discrepancy will serve as a benchmark for evaluating \nthe success of the proposed strategy.  \n \n4. Test and validate the proposed ABR strategies using simulations driven by real -\nworld mobile bandwidth traces and cont rolled, synthetic RTT profiles on different \nnetwork conditions:  This objective entails rigorous testing and validation of the \nproposed ABR strategies using experimental setups within the simulation environment \nthat mimic diverse network conditions. The val idation process will employ both objective \nmetrics, such as latency, buffering ratio, quality switch frequency, and playback latency \ndiscrepancy, and a composite QoE score to comprehensively evaluate the ABR's \nperformance and effectiveness in emulated real -world scenarios. Subjective QoE \nassessments are acknowledged as a valuable future validation step.  \n \n1.4 Justification of the Study  \nThis research is justified by the ever -increasing importance of video streaming in today's digital \nworld and the critical ne ed to address the persistent challenge of latency, particularly in mobile \nnetworks. Several factors underscore the significance and timeliness of this study:  \n1. Industry Relevance and User Demand:  The explosive growth of mobile video \nstreaming and the increasing user demand for seamless, high -quality experiences make \nlatency optimization a critical concern for the video streaming industry. Minimizing \nlatency (including startup times, stalls, and pla yback discrepancies between viewers) \ndirectly addresses user expectations, enhances QoE, and improves user engagement, \nwhich translates to increased revenue and subscriber growth for content providers \n(Dobrian et al., 2011). Furthermore, latency optimizati on aligns with the industry's need \nfor efficient utilization of mobile network resources, ensuring the sustainability of mobile \ndata networks (Dahlman et al., 2014).  \n \n2. Addressing Research Gaps:  This project directly addresses significant research gaps \nin the existing literature on video streaming latency optimization. By focusing on network \nRTT as a primary and distinct latency factor, systematically evaluating its impact through \ncontrolled simulation, and quantifying the resultant playback latency discrepan cy \nbetween users, this research aims to bridge critical gaps in current knowledge and",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 4,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "ly evaluating its impact through \ncontrolled simulation, and quantifying the resultant playback latency discrepan cy \nbetween users, this research aims to bridge critical gaps in current knowledge and\n\n[Page 6]\ncontribute to the advancement of the field. The project also explores how understanding \nthese fundamental RTT impacts is foundational for addressing latency in more compl ex \napplications like VR/360 video and live streaming.  \n \n3. Potential for Innovation and Impact:  This project leverages a controlled simulation \nframework to enable the development and evaluation of a novel RTT -aware ABR \nalgorithm ( LatencyAwareAbr ). The insights  gained and any subsequent algorithm \nenhancements to explore new possibilities for latency reduction and develop more \nintelligent and data -driven optimization strategies (Mao et al., 2017). The development of \na novel ABR strategy with demonstrably reduced latency and enhanced QoE, \nparticularly in managing viewer discrepancy, has the potential to significantly impact the \nvideo streaming industry and improve the user experience for millions of mobile video \nconsumers. The simulation framework itself is a contr ibution, enabling this controlled \nstudy.  \n \n1.5 Scope of the Study  \nThe scope of this project is focused on analyzing and optimizing client -side perceived latency \nand playback discrepancy in adaptive video streaming, particularly in mobile network \nenvironment s, through simulation -based evaluation. While the research will draw upon insights \nfrom studies using real -world data and experimental setups, the primary focus will be on:  \n1. Mobile Networks:  The study will primarily focus on video streaming optimization for  \nsimulated mobile networks (e.g., utilizing HSDPA bandwidth traces representative of \n4G/LTE -like conditions) and their inherent challenges of fluctuating bandwidth and \ncontrolled high delays (RTT) (Dahlman et al., 2014). The optimization strategies \ndevelop ed will be specifically tailored to address the characteristics and constraints of \nmobile network environments. While the findings may be relevant to other network types, \nextending the findings to fixed networks or other broadband networks is outside the \nprimary scope of this project and may require further investigation.  \n \n2. Latency as the Primary Metric Set:  The project will prioritize latency as the primary \nmetric set for optimization and QoE enhancement. This includes startup delay, buffering \nevents (stall s), and critically, the relative playback progression between clients (viewer \ndiscrepancy). While other QoE factors such as video quality (average bitrate) and quality \nswitch frequency will be considered as important balancing factors and outcomes, the \ncentral focus will remain on minimizing latency and improving responsiveness, especially \nfor delay -sensitive applications.  \n \n3. Adaptive Bitrate Streaming Logic:  The research will concentrate on client -side \nadaptive bitrate streaming techniques, specifically the logic within HTTP -based adaptive \nstreaming protocols like DASH and HLS (though protocol specifics are abstracted in the \nsimulation). While other streaming techniques exist, adaptive HTTP streaming is the",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 5,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "within HTTP -based adaptive \nstreaming protocols like DASH and HLS (though protocol specifics are abstracted in the \nsimulation). While other streaming techniques exist, adaptive HTTP streaming is the\n\n[Page 7]\ndominant paradigm for video delivery over the intern et, making the ABR client logic the \nmost relevant and impactful area of study for this work.  \n \n4. Foundational Latency Optimization for General and Immersive Applications:  The \nproject will explore fundamental latency optimization techniques applicable to a bro ader \nrange of video streaming applications. However, the primary focus will remain on \ngeneral latency optimization techniques applicable to a broader range of video streaming \napplications, with the understanding of RTT impact being foundational for more \nspecialized areas like VR and 360 -degree video serving as a specific use case \nmotivation, though specific tile -based or VR -centric ABR optimizations are outside the \nimmediate scope of the implemented work.  \n \n5. Algorithm Development and Evaluation through Simula tion:  The project will \nencompass the development of a novel latency -aware adaptive bitrate algorithm \n(LatencyAwareAbr ) and its rigorous evaluation and validation through simulations. \nHowever, the project will not involve the deployment of a fully functiona l, production -\nready video streaming platform. The focus will be on developing and validating the core \nalgorithms and optimization strategies within the simulation testbed, leaving the \nimplementation and deployment at scale for future work.  \n \nBy focusing on these specific areas, the project aims to provide a deep and impactful \ninvestigation into latency optimization for video streaming, addressing critical challenges and \ncontributing valuable knowledge to the field.  \nReferences  \ni. Akhshabi, S., Begen, A. C., & Do vrolis, C. (2011). An experimental evaluation of rate -\nadaptation algorithms in adaptive streaming over HTTP. Proceedings of the 2nd Annual \nACM Multimedia Systems Conference (MMSys '11) , 157\u2013168. \nii. Balachandran, A., Sekar, V., Akella, A., Seshan, S., Stoica, I., & Zhang, H. (2013). \nDeveloping a predictive model of quality of experience for Internet video. Proceedings of \nthe ACM SIGCOMM Conference , 339\u2013350. \niii. da Costa Filho, R. I. T., Lautenschlager, W., Kagami, N., Roesler, V., & Gaspary, L. P. \n(2016). Network fortune cookie: Using network measurements to predict video streaming \nperformance and QoE. 2016 IEEE Global Communications Conference (GLOBECOM) , \n1\u20136. \niv. Dahlman, E., Mildh, G., Parkvall, S., Peisa, J., Sachs, J., Sel\u00e9n, Y., & Sk\u00f6ld, J. (2014). \n5G wireless access: Requirements and realization. IEEE Communications Magazine , \n52(12), 42\u201347. \nv. Dobrian, F., Sekar, V., Awan, A., Stoica, I., Chuang, D., Ganjam, A., . .. Zhang, H. \n(2011). Understanding the impact of video quality on user engagement. Proceedings of \nthe ACM SIGCOMM Conference (SIGCOMM '11) , 362\u2013373. \nvi. Fan, C. -L., Lee, J., Lo, W. -C., Huang, C. -Y., Chen, K. -T., & Hsu, C. -H. (2017). Fixation \nprediction for 360  video streaming in head -mounted virtual reality. Proceedings of the",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 6,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": ", 362\u2013373. \nvi. Fan, C. -L., Lee, J., Lo, W. -C., Huang, C. -Y., Chen, K. -T., & Hsu, C. -H. (2017). Fixation \nprediction for 360  video streaming in head -mounted virtual reality. Proceedings of the\n\n[Page 8]\n27th Workshop on Network and Operating Systems Support for Digital Audio and Video \n(NOSSDAV '17) , 67\u201372. \nvii. Mao, H., Netravali, R., & Alizadeh, M. (2017). Neural adaptive video streaming wit h \npensieve. Proceedings of the Conference of the ACM Special Interest Group on Data \nCommunication (SIGCOMM '17) , 197 -210. \nviii. Oyman, O., & Singh, S. (2012). Quality of experience for HTTP adaptive streaming \nservices. IEEE Communications Magazine , 50(4), 20\u201327. \nix. Petrangeli, S., Swaminathan, V., Hosseini, M., & De Turck, F. (2017). An HTTP/2 -based \nadaptive streaming framework for 360 virtual reality videos. Proceedings of the 2017 \nACM on Multimedia Conference (MM '17) , 306\u2013314. \nx. Petrangeli, S., Famaey, J., Claeys, M., Latr\u00e9, S., & De Turck, F. (2015). QoE -driven rate \nadaptation heuristic for fair adaptive video streaming. ACM Transactions on Multimedia \nComputing, Communications, and Applications , 12(2), Article 28.  \nxi. Sodagar, I. (2011). The MPEG -DASH standard for multimedia streaming over the \nInternet. IEEE Multimedia , 18(4), 62\u201367. \nxii. Yin, X., Jindal, A., Sekar, V., & Sinopoli, B. (2015). A control -theoretic approach for \ndynamic adaptive video streaming over HTTP. SIGCOM M Computer Communication \nReview , 45(4), 325\u2013338.",
    "metadata": {
      "source_file": "documents/Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1).pdf",
      "file_type": "pdf",
      "chunk_number": 7,
      "title": "Chapter 1_ Analyzing and Optimizing Latency in Video Streaming -mod(1)(1)",
      "file_size": 159245,
      "page_count": 8
    }
  },
  {
    "text": "[Page 1]\nChapter 2: Literature Review  \n2.1 Overview of Video Streaming Technology  \n2.1.1 Introduction to Video Streaming  \nVideo streaming is the process of transmitting video content over a network, allowing users to \nwatch it in real -time without downloading the entire file beforehand. This involves dividing the \nvideo into small segments, which are then transmitted sequential ly and played back by the client \n(Sodagar, 2011). A key performance metric is latency. In the context of this research, latency \nencompasses not only the delay between content creation and initial playback (startup delay) \nand interruptions during playback ( stalls/rebuffering), but also the relative differences in \nplayback progression between concurrent viewers experiencing heterogeneous network \nconditions. Minimizing these forms of latency is crucial for a positive user experience, especially \nin today's digi tal world where high -quality video streaming is increasingly demanded, particularly \non mobile devices. The ever -increasing demand for high -quality video streaming necessitates \ninnovative solutions to minimize latency, defined as the delay between content c reation and \nplayback. High latency significantly impacts user engagement and potential revenue. Factors \ncontributing to latency include network conditions (bandwidth, Round -Trip Time (RTT) / delay, \npacket loss), server performance, video encoding schemes, and client -side factors (buffer \nmanagement, adaptation strategies). Adaptive streaming techniques are crucial for mitigating \nthe impact of network variability (Oyman & Singh, 2012).  \n2.1.2 Historical Evolution of Streaming Protocols  \nEarly video streaming so lutions often struggled with maintaining consistent quality under varying \nnetwork conditions. The rise of adaptive bitrate streaming addressed this challenge. Three \nprominent adaptive HTTP streaming protocols have emerged:  \n1. MPEG -DASH (Dynamic Adaptive Strea ming over HTTP):  An international standard \ndeveloped by ISO/IEC, DASH provides a framework for adaptive HTTP streaming, \nenabling clients to dynamically adjust the bitrate based on network conditions and device \ncapabilities (Sodagar, 2011). It utilizes segm ented video delivery and allows clients to \nselect video segments in various qualities. DASH\u2019s focus on adaptation to diverse \nnetwork conditions directly contributes to its ability to minimize latency issues.  \n2. HTTP Live Streaming (HLS):  Developed by Apple, H LS is another adaptive streaming \nprotocol that allows for dynamic adjustment of bitrate through segmented delivery over \nHTTP, providing video segments in multiple qualities (Li et al., 2014). The fragmented \ndelivery inherent in HLS helps reduce the impact of transmission delays.",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 0,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "itrate through segmented delivery over \nHTTP, providing video segments in multiple qualities (Li et al., 2014). The fragmented \ndelivery inherent in HLS helps reduce the impact of transmission delays.\n\n[Page 2]\n3. Smooth Streaming:  Developed by Microsoft, Smooth Streaming is a segmented HTTP \nstreaming technique providing similar capabilities to DASH and HLS for adaptive bitrate \ncontrol and thus contributing to improved latency (Akhshabi et al ., 2013).  \nThese protocols differ in how they segment the video (DASH supports both fixed and variable -\nlength segments, while HLS uses fixed -length segments), the way they signal quality levels to \nthe client, and the methods used for adaptive bitrate select ion. However, all aim to minimize \nlatency via efficient adaptation to dynamically changing network conditions (Akhshabi et al., \n2013; Li et al., 2014).  \n2.1.3 Adaptive Streaming Mechanisms  \nAdaptive HTTP streaming (like DASH and HLS) significantly improves v ideo playback quality by \ndynamically adapting to fluctuating network conditions and device capabilities (Sodagar, 2011). \nKey mechanisms include:  \n1. Adaptive Bitrate Selection:  The client continuously monitors network conditions (e.g., \nbandwidth, Round -Trip Ti me (RTT) / latency , packet loss) and selects a bitrate that \nmaximizes QoE without causing buffer underruns. Algorithms for bitrate selection must \nconsider the tradeoff between achieving high quality and preventing interruptions by \ndynamically balancing ban dwidth and latency. This usually requires forecasting future \nnetwork conditions to anticipate network limitations (Balachandran et al., 2013).  \n2. Segment -Level Adaptation:  Adaptive streaming uses segmented video delivery, \nallowing the client to request specif ic video segments at different qualities based on \navailable bandwidth and latency (Sodagar, 2011). The small segment sizes contribute to \nbetter adaptation to varying network bandwidth, which helps minimize delays.  \n3. Buffer Management:  Clients use buffers to store received segments, smoothing out \nshort -term fluctuations in network bandwidth and preventing interruptions in playback. \nBuffer management algorithms must consider the tradeoff between minimizing buffering \ndelays and managing memory usage on client de vices (Miller et al., 2012).  \n2.1.4 Role of Standards and Frameworks  \nStandardization has played a key role in ensuring interoperability and efficient implementation of \nadaptive streaming. The most significant is the MPEG -DASH standard, which provides a \ncomm on framework for adaptive HTTP streaming, addressing challenges related to latency, \nnetwork variability, and device heterogeneity. Other relevant standards and frameworks (e.g., \nHLS and Smooth Streaming) support similar adaptive streaming functionalities a nd contribute to \nthe overall efficiency and reliability of video streaming over various network environments. \nIndustry initiatives and working groups are focused on ongoing refinements of standards and \nprotocols to improve performance and enhance user expe rience in mobile environments where \nthe bandwidth can fluctuate (Oyman & Singh, 2012). Research efforts focus on innovating \nquality adaptation algorithms that prioritize low latency and minimize the negative impact of \nbuffering and low resolution (Yin et a l., 2015).",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 1,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "n & Singh, 2012). Research efforts focus on innovating \nquality adaptation algorithms that prioritize low latency and minimize the negative impact of \nbuffering and low resolution (Yin et a l., 2015).\n\n[Page 3]\n2.2 Factors Contributing to Latency in Video Streaming  \n2.2.1 Network Conditions  \nNetwork conditions significantly impact video streaming latency. Key factors include:  \n1. Bandwidth:  Insufficient bandwidth leads to increased buffering and reduced vide o \nquality. Lower bandwidth necessitates lower bitrates, potentially impacting the viewing \nexperience (Dobrian et al., 2011). Fluctuations in bandwidth, especially prevalent in \nmobile networks, cause significant challenges in maintaining smooth playback.  \n2. Delay (Round -Trip Time - RTT):  Network delay, fundamentally characterized by the \nRound -Trip Time (RTT) for data packets, directly adds to overall latency. High RTT \nsignificantly impacts the agility of ABR decision loops, as feedback on throughput and \nbuffe r status is delayed. Each segment request and initial data reception is penalized by \nthe RTT, prolonging download times even if instantaneous bandwidth is high. This is \nparticularly critical during startup and recovery from stalls. High delay in mobile \nnetworks, particularly in broadband networks, exacerbates latency issues (Dahlman et \nal., 2014).  \n3. Packet Loss:  Packet loss, where data packets are lost during transmission, \nnecessitates retransmission, significantly increasing latency and potentially leading t o \ninaccurate throughput estimations by the ABR if not properly accounted for. Mobile \nnetworks are particularly susceptible to packet loss due to signal interference and \nmobility (Oyman & Singh, 2012).  \n4. Jitter:  Jitter, variations in the time between packet a rrivals (or inter -packet delay \nvariance), causes uneven playback and disrupts the viewing experience. High jitter can \nmake consistent throughput prediction difficult for ABR algorithms and can lead to buffer \nmismanagement if not smoothed out effectively by  the playout buffer. Jitter can be \nparticularly problematic in wireless environments due to interference and signal \nfluctuations (Akhshabi et al., 2013).  \nAdaptive streaming protocols attempt to mitigate the effects of fluctuating bandwidth and high \ndelay b y dynamically adjusting the video quality (bitrate) based on observed network conditions. \nHowever, these protocols may not be perfectly efficient in reacting to unpredictable changes in \nnetwork conditions (Yin et al., 2015). Network congestion further exac erbates latency, as \nincreased traffic delays and packet loss.  \n2.2.2 Server Performance and Content Placement  \nServer performance and content placement are crucial to minimizing latency.  \n1. Server Load:  High server load leads to increased processing times, dela yed segment \ndelivery, and increased latency (Akhshabi et al., 2013). Efficient server configurations \nand load balancing techniques are essential for distributing the load across multiple \nservers and minimizing the impact of high server load.",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 2,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "(Akhshabi et al., 2013). Efficient server configurations \nand load balancing techniques are essential for distributing the load across multiple \nservers and minimizing the impact of high server load.\n\n[Page 4]\n2. Content Placem ent: Content placement strategies (i.e., where to store video content) \nplay a critical role in minimizing latency (Golrezaei et al., 2013). Content delivery \nnetworks (CDNs) improve latency by strategically locating content servers closer to \nusers, reducing  the distance data needs to travel to reach the client.  \n3. Server Processing:  The time taken for the server to process incoming requests and \nprepare segments for delivery also contributes to latency. Efficient server -side \nprocessing techniques, including optimized video encoding and segment generation, are \ncritical for minimizing t his component of latency. Server -side traffic shaping and load \nbalancing can also play a crucial role in minimizing latency (Akhshabi et al., 2013).  \n2.2.3 Video Encoding and Segmentation  \nVideo encoding and segmentation methods significantly influence laten cy. \n1. Video Encoding Schemes:  The complexity of video encoding schemes directly impacts \nprocessing time, affecting latency. More complex encodings (e.g., higher resolution, \nhigher bitrates) demand increased processing power, resulting in increased latency, \nespecially on low -power mobile devices (Yin et al., 2015). (Note: This study assumes \nconstant encoding parameters for ABR evaluation to isolate network effects).  \n2. Segment Length:  The length of video segments affects both the frequency of quality \nadaptation a nd overhead. Shorter segments enable more frequent adjustments to video \nquality based on network conditions, improving the viewing experience. However, they \nalso introduce overhead due to increased signaling and increased transmission of \nsmaller packets (D obrian et al., 2011). Longer segments reduce overhead but result in \nslower adaptation to changes in network conditions. The optimal segment length \ninvolves a complex trade -off between these two factors. (Note: This study uses a fixed \nsegment duration, as s pecified in Chapter 3, to provide a consistent basis for ABR \nevaluation).  \n2.2.4 Client -Side Factors  \nClient -side factors play a critical role in managing latency.  \n1. Buffering:  Clients use buffers to store incoming video segments, smoothing out short -\nterm fluc tuations in network bandwidth. Insufficient buffer size leads to buffering delays \nand stutters, which negatively impact the viewing experience (Miller et al., 2012).  \n2. Rate Adaptation:  Adaptive bitrate (ABR) algorithms dynamically adjust the video quality \n(bitrate) based on observed network conditions and client device capabilities (Yin et al., \n2015). Efficient ABR algorithms are crucial for maintaining smooth playback while \nminimizing latency, but they also add complexity. The design and evaluation of such \nABR algorithms, particularly those sensitive to RTT, are a central focus of this research.  \n3. Device Processing Power:  The processing power of the client device significantly \nimpacts the speed of video decoding and processing, which directly influences playbac k \nlatency. Low processing power on mobile devices exacerbates latency issues (Yin et al., \n2015). Client -side caching can help reduce latency by storing frequently accessed video",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 3,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "influences playbac k \nlatency. Low processing power on mobile devices exacerbates latency issues (Yin et al., \n2015). Client -side caching can help reduce latency by storing frequently accessed video\n\n[Page 5]\nsegments locally, but its effectiveness is limited by device storage capacity.  (Note: This \nstudy assumes idealized and consistent client device processing power to isolate the \nimpact of network conditions and ABR logic).  \nClient -side buffer management and playback algorithms are also essential for efficient latency \nmanagement. These must be optimized to ensure smooth playback and mitigate the impact of \nfactors such as network jitter and varying bandwidth conditions (Miller et al., 2012).  \n2.3 Existing Optimization Techniques for Video Streaming \nLatency  \n2.3.1 Network -Level Optimizations  \nNetwork -level optimizations aim to improve the underlying network infrastructure to reduce \nlatency. Key techniques include:  \n1. Multipath Streaming:  This technique utilizes multiple network paths to transmit video \ndata, improving bandwidth utilization and red ucing latency. By diversifying the \ntransmission paths, multipath streaming can mitigate the impact of congestion or failures \non a single path, ensuring smoother playback (Qian et al., 2016). However, it adds \ncomplexity in terms of path selection, managemen t, and coordination, and may not \nalways yield significant latency improvements.  \n \n2. Bandwidth Aggregation:  This approach combines multiple network interfaces (e.g., Wi -\nFi and cellular) to increase the overall available bandwidth for video streaming. This \nimpr oves the robustness of the connection and enhances the download speed, leading to \nreduced latency. However, it requires managing multiple interfaces and protocols, \npotentially impacting performance and increasing complexity. It may also suffer from \ninterfe rence issues with specific links or configurations (Golrezaei et al., 2013).  \n \n3. Proactive Caching and Pre -fetching:  This technique reduces latency by storing popular \ncontent closer to users, minimizing data retrieval time. Proactive caching involves \npredicti ng user demand and pre -fetching content to edge servers or local caches. While \nthis can significantly improve latency for popular content, predicting user demand \naccurately is challenging and maintaining cache consistency across a distributed network \nmay p ose difficulties. Inefficient cache management strategies could lead to poor \nperformance and wasted resources. The implementation complexity for dynamic caching \nis high (Golrezaei et al., 2013).  \n2.3.2 Server -Side Optimizations",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 4,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "ache management strategies could lead to poor \nperformance and wasted resources. The implementation complexity for dynamic caching \nis high (Golrezaei et al., 2013).  \n2.3.2 Server -Side Optimizations\n\n[Page 6]\nServer -side optimizations focus on enhancing server performance and content delivery efficiency \nto minimize latency. Key techniques include:  \n1. Optimized Content Placement:  Strategically placing content across multiple servers \nreduces the average distance dat a needs to travel to reach the user, minimizing latency. \nCDNs employ this approach extensively by distributing content across geographically \ndispersed data centers (Dahlman et al., 2014). However, efficient content placement \nrequires sophisticated algorith ms and detailed knowledge of network topology and user \naccess patterns. Poor placement strategies could result in longer latency for some users.  \n \n2. Load Balancing and Traffic Shaping:  Load balancing distributes streaming requests \nevenly across multiple serve rs, preventing any single server from being overloaded and \nminimizing latency. Traffic shaping techniques control data transmission rates, ensuring \nthat bandwidth is allocated fairly and preventing congestion (Akhshabi et al., 2013). \nSophisticated load bal ancing algorithms and traffic shaping techniques are needed to \nmanage fluctuating network demands and maximize efficiency.  \n \n3. Edge Computing and CDNs:  Edge computing pushes processing and content closer to \nend users, reducing latency significantly. CDNs comb ine edge computing with \ndistributed server infrastructure to improve content delivery efficiency and reduce \nlatency. The benefits of edge computing are limited by the need to deploy and maintain \nextensive edge server infrastructure. Efficient management an d coordination of the edge \nservers become extremely critical (Akhshabi et al., 2013).  \n(Note: Similar to network -level, these are contextual. This study's ABR operates at the client, \nreacting to the network conditions shaped by such server -side strategies.)  \n2.3.3 Client -Side Optimizations  \nClient -side optimizations improve the client\u2019s ability to manage video playback and reduce the \nimpact of network fluctuations to minimize latency. Key techniques include:  \n1. Improved Adaptation Strategies:  Adaptation strategie s dynamically adjust the video \nquality (bitrate) based on observed network conditions and client capabilities. Algorithms \nreact swiftly to network changes, prioritizing QoE metrics such as startup delay and \nbuffering frequency. The complexity of adaptation  algorithms increases with the goal of \nimproving efficiency and user experience and accurate prediction of future network \nconditions is critical (Yin et al., 2015). Many ABR algorithms primarily use bandwidth \nestimations (e.g., BOLA by Spiteri et al., 2016 ) or buffer occupancy (e.g., buffer -based \napproaches like that in Akhshabi et al., 2011) to make decisions.  \n2. Efficient Buffer Management:  Optimizing buffer sizes, pre -fetching segments, and \nmaking dynamic buffer adjustments are essential for minimizing buff ering delays and \nmaintaining continuous playback (Miller et al., 2012). Efficient buffer management",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 5,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "s, pre -fetching segments, and \nmaking dynamic buffer adjustments are essential for minimizing buff ering delays and \nmaintaining continuous playback (Miller et al., 2012). Efficient buffer management\n\n[Page 7]\ninvolves a complex tradeoff between minimizing latency and managing memory usage \non the client device.  \n3. Low-Latency ABR Algorithms:  Low-latency ABR algorithm s prioritize minimizing \nplayback latency. These may involve heuristics that quickly assess network conditions or \nadvanced techniques like machine learning to predict future network conditions and \noptimize bitrate decisions in real -time (Dahlman et al., 201 4). Some approaches \nexplicitly incorporate delay measurements or RTT estimates (e.g., an area this research \nexplores with LatencyAwareAbr ), while others focus on aggressive buffer targets or \nfaster quality down -switching. Developing and implementing low -latency ABR algorithms \ncan be challenging given the complex interactions between network conditions and user \nexperience.  \n2.3.4 Emerging Technologies and Techniques  \nEmerging technologies offer further potential for minimizing latency in video streaming:  \n1. Machine Learning for Latency Prediction:  Machine learning models can analyze \nhistorical network data to predict future latency and/or bandwidth and optimize bitrate \ndecisions. These models can improve the accuracy and timeliness of network condition \nassess ment, enabling more proactive and efficient adaptation to prevent service \ndisruptions. Developing accurate predictive models is computationally intensive and \nhighly dependent on the quality and volume of data (Balachandran et al., 2013; Mao et \nal., 2017). While the ABR evaluated in this study ( LatencyAwareAbr ) uses simpler \nheuristic predictors, the potential for ML integration represents a significant avenue for \nfuture enhancement.  \n2. Viewport Prediction and Tile -Based Streaming:  For 360 -degree and VR videos, this \ntechnique prioritizes tiles within the predicted viewing area to reduce the amount of data \nthat needs to be transmitted, minimizing latency. This approach requires efficient \nviewport prediction algorithms which add complexity (Akhshabi et al., 2013). Accurate \nviewport prediction is crucial for minimizing latency, but is highly dependent on the \naccuracy of user head movement prediction. (Note: While highly relevant for overall \nlatency in VR, specific tile -based optimizations are outside the scope of the  ABR logic \nevaluated in this study, which focuses on general ABR latency.)  \n2.4 Gaps in the Literature on Video Streaming Latency \nOptimization  \n2.4.1 Latency -Aware Adaptation Needs  \nCurrent adaptive streaming protocols (DASH, HLS) often prioritize high bitrates to maximize \nvideo quality, potentially overlooking the importance of minimizing latency. In mobile network \nenvironments with fluctuating bandwidth and high delay, this prioriti zation of bitrate over latency \ncan lead to suboptimal Quality of Experience (QoE), manifesting as buffering, startup delays,",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 6,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "ork \nenvironments with fluctuating bandwidth and high delay, this prioriti zation of bitrate over latency \ncan lead to suboptimal Quality of Experience (QoE), manifesting as buffering, startup delays,\n\n[Page 8]\nand frequent quality changes. Existing solutions prioritize high bitrates over low latency, leading \nto suboptimal QoE in mobile net works (Petrangeli et al., 2017). There is a clear need for \nalgorithms that explicitly prioritize low latency by robustly incorporating factors like RTT into their \ncore decision -making process, while maintaining acceptable video quality, particularly for de lay-\nsensitive applications like video conferencing and interactive gaming. These algorithms should \nspecifically address the challenges of unpredictable network conditions inherent in mobile \nenvironments.  \n2.4.2 Network Delay versus Bandwidth Focus  \nMuch of t he existing research on video streaming latency focuses primarily on bandwidth \noptimization, overlooking the significant impact of network delay (particularly RTT). While \nbandwidth limitations can impact video quality and cause buffering, network delay dir ectly \ncontributes to latency, regardless of available bandwidth. Network delay (RTT) is often the \ndominant factor affecting video streaming performance in mobile environments where delays \nexceeding critical thresholds significantly limit achievable bitrate s and video quality (Costa Filho \net al., 2016). In contrast, bandwidth in mobile networks, particularly broadband networks, is \nhighly variable, but this variability is often less impactful than sustained high delay on user \nexperience. More research is need ed to understand the complex interplay between bandwidth \nand delay (RTT) in different network environments (Oyman & Singh, 2012), and to develop \noptimization strategies that effectively manage both aspects to minimize latency. This study \naims to contribute  to this area by specifically isolating and evaluating the impact of RTT.  \n2.4.3 Device and Network Heterogeneity  \nMost existing video streaming optimization algorithms assume homogenous network conditions \nand device capabilities, ignoring the significant di versity in real -world scenarios (Petrangeli et \nal., 2017). Mobile devices vary widely in processing capabilities, screen sizes, and resolutions, \nand mobile networks exhibit significant variability in bandwidth and latency (including RTT). The \nlack of consi deration for these heterogeneities means that one -size-fits-all algorithms often fail \nto provide optimal QoE. This study specifically investigates the impact of network RTT \nheterogeneity on client performance and playback discrepancy. Algorithms and archit ectures \nshould be designed to explicitly take into account this device and network heterogeneity, \ntailoring optimization strategies to the individual capabilities and constraints of each device and \nnetwork condition. A more holistic approach to optimizatio n is required to consider how different \ndevices may demand different quality levels at different network conditions.  \n2.4.4 Emerging Needs in 360 -Degree and VR Streaming  \nThe rapidly growing popularity of 360 -degree and VR video streaming introduces unique \nchallenges for latency optimization. These immersive experiences require significantly higher \nbandwidths and more sophisticated delivery techniques to achieve acceptable QoE. Viewport \nprediction and tile -based streaming, which aims to deliver only the visib le parts of the video, are \npromising approaches for optimizing bandwidth usage. However, viewport prediction algorithms",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 7,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "ort \nprediction and tile -based streaming, which aims to deliver only the visib le parts of the video, are \npromising approaches for optimizing bandwidth usage. However, viewport prediction algorithms\n\n[Page 9]\nmust be very accurate to avoid significant quality degradation (Akhshabi et al., 2013). Further, \nadaptation strategies must be tailored to handle the specific characteristics of VR videos, \naddressing issues such as spatial segmentation and quality zone selection, which necessitates \nmore research to develop efficient and robust algorithms (Fan et al., 2017). Adaptive algorithms \nthat priorit ize low latency for VR and 360 -degree video, that efficiently respond to changing \nnetwork conditions while minimizing buffering and quality changes are needed. Understanding \nthe fundamental impact of RTT on general ABR performance, as explored in this stud y, is a \nfoundational step towards addressing these more complex scenarios.  \nReferences  \ni. Akhshabi, S., Anantakrishnan, L., Dovrolis, C., & Begen, A. C. (2013). Server -based \ntraffic shaping for stabilizing oscillating adaptive streaming players. Proceedings of  the \n23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and \nVideo (NOSSDAV '13) , 19\u201324. \nii. *Akhshabi, S., Begen, A. C., & Dovrolis, C. (2011). An experimental evaluation of rate -\nadaptation algorithms in adaptive streaming over HTTP. Proceedings of the 2nd Annual \nACM Multimedia Systems Conference (MMSys '11), 157 \u2013168.* (Added here as it's \nrelevant for buffer -based approaches)  \niii. Balachandran, A., Sekar, V., Akella, A., Seshan, S., Stoica, I., & Zhang, H. (2013). \nDeveloping a predictive mo del of quality of experience for Internet video. Proceedings of \nthe ACM SIGCOMM Conference , 339 \u2013350. \niv. Dahlman, E., Mildh, G., Parkvall, S., Peisa, J., Sachs, J., Sel\u00e9n, Y., & Sk\u00f6ld, J. (2014). \n5G wireless access: Requirements and realization. IEEE Communica tions Magazine , \n52(12), 42 \u201347. \nv. da Costa Filho, R. I. T., Lautenschlager, W., Kagami, N., Roesler, V., & Gaspary, L. P. \n(2016). Network fortune cookie: Using network measurements to predict video streaming \nperformance and QoE. 2016 IEEE Global Communication s Conference (GLOBECOM) , \n1\u20136. \nvi. Dobrian, F., Sekar, V., Awan, A., Stoica, I., Chuang, D., Ganjam, A., ... Zhang, H. \n(2011). Understanding the impact of video quality on user engagement. Proceedings of \nthe ACM SIGCOMM Conference (SIGCOMM '11) , 362 \u2013373. \nvii. Fan, C .-L., Lee, J., Lo, W. -C., Huang, C. -Y., Chen, K. -T., & Hsu, C. -H. (2017). Fixation \nprediction for 360 video streaming in head -mounted virtual reality. Proceedings of the \n27th Workshop on Network and Operating Systems Support for Digital Audio and Video \n(NOSSDAV '17) , 67\u201372. \nviii. Golrezaei, N., Molisch, A. F., Dimakis, A. G., & Caire, G. (2013). Femto -caching and \ndevice -to-device collaboration: A new architecture for wireless video distribution. IEEE \nCommunications Magazine, 51 (4), 142 -149. \nix. Li, Z., Zhu, X., Gahm,  J., Pan, R., Hu, Y., Begen, A. C., & Oran, D. (2014). Probe and \nadapt: Rate adaptation for HTTP video streaming at scale. IEEE Journal on Selected \nAreas in Communications, 32 (4), 719 -733.",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 8,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": ", Gahm,  J., Pan, R., Hu, Y., Begen, A. C., & Oran, D. (2014). Probe and \nadapt: Rate adaptation for HTTP video streaming at scale. IEEE Journal on Selected \nAreas in Communications, 32 (4), 719 -733.\n\n[Page 10]\nx. Mao, H., Netravali, R., & Alizadeh, M. (2017). Neural adaptive vide o streaming with \npensieve. Proceedings of the Conference of the ACM Special Interest Group on Data \nCommunication (SIGCOMM '17) , 197 -210. \nxi. Miller, K., Ramakrishnan, K. K., & Polyzos, G. C. (2012). Buffer -aware adaptation for \nHTTP adaptive streaming. 2012 IEE E International Conference on Multimedia and Expo \nWorkshops , 380 -385. \nxii. Oyman, O., & Singh, S. (2012). Quality of experience for HTTP adaptive streaming \nservices. IEEE Communications Magazine , 50(4), 20 \u201327. \nxiii. Petrangeli, S., Swaminathan, V., Hosseini, M., & De Turck, F. (2017). An HTTP/2 -based \nadaptive streaming framework for 360 virtual reality videos. Proceedings of the 2017 \nACM on Multimedia Conference (MM '17) , 306 \u2013314. \nxiv. Petrangeli, S., Famaey, J., Claeys, M., Latr\u00e9, S., & De Turck, F. (2015). QoE -driven rate \nadaptation heuristic for fair adaptive video streaming. ACM Transactions on Multimedia \nComputing, Communications, and Applications , 12(2), Article 28.  \nxv. Qian, F., Ji, L ., Han, B., & Gopalakrishnan, V. (2016). Optimizing 360 video delivery over \ncellular networks. Proceedings of the 5th workshop on All things cellular: Operations, \napplications and challenges , 1-6. \nxvi. Sodagar, I. (2011). The MPEG -DASH standard for multimedia s treaming over the \nInternet. IEEE Multimedia , 18(4), 62 \u201367. \nxvii. Spiteri, K., Sitaraman, R., & Sparacio, D. (2016). BOLA: Near -optimal bitrate adaptation \nfor online videos. IEEE/ACM Transactions on Networking, 28 (4), 1 -14. (Example of a \nnotable ABR algorithm, BO LA, which focuses on buffer and is a good contrast to RTT -\naware approaches).  \nxviii. Yin, X., Jindal, A., Sekar, V., & Sinopoli, B. (2015). A control -theoretic approach for \ndynamic adaptive video streaming over HTTP. SIGCOMM Computer Communication \nReview , 45(4), 3 25\u2013338.",
    "metadata": {
      "source_file": "documents/Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1).pdf",
      "file_type": "pdf",
      "chunk_number": 9,
      "title": "Chapter 2_ Literature Review - Analyzing and Optimizing Latency in Video Streaming - mod(1)",
      "file_size": 257455,
      "page_count": 10
    }
  },
  {
    "text": "[Page 1]\nChapter 5: Conclusion and Future Work  \n5.1 Summary of the Study  \nThis project addressed the persistent challenge of optimizing video streaming performance over \ninherently variable mobile networks, with a specific focus on mitigating the negative impacts of \nnetwork latency often overlooked by traditional Adaptive Bitrate  (ABR) algorithms. High latency, \nmanifesting as startup delays and playback stalls (buffering), significantly degrades the Quality \nof Experience (QoE) for end -users. The primary objective was to design, implement, and \nevaluate a latency -aware ABR algorithm  capable of improving viewing stability compared to \nconventional buffer -based approaches.  \nTo achieve this, a mixed -methods approach, outlined in Chapter 3, was partially implemented. A \nsimulation framework was developed to evaluate ABR performance. This fr amework utilized \nreal-world mobile network bandwidth  traces from the HSDPA dataset to capture realistic \nbandwidth variability across diverse scenarios (bus, metro, train, car, ferry). Crucially, as the \nchosen dataset lacked network Round -Trip Time (RTT) da ta, fluctuating synthetic network delay  \ntraces were generated and used alongside the real bandwidth data. This allowed for testing the \ncore principle of incorporating delay awareness into the ABR decision process. Two algorithms \nwere compared: a baseline B uffer-Based (BB) ABR and the proposed Latency -Aware (LA) ABR, \nwhich uses simple prediction models for throughput and delay and explicitly factors estimated \nRTT into its bitrate selection logic. Performance was assessed using key metrics including \nstartup d elay, buffering ratio, average bitrate, quality switch frequency, and a simplified QoE \nscore.  \n5.2 Summary of Key Findings  \nThe simulation results, presented and discussed in Chapter 4, yielded several key findings \nregarding the comparative performance of th e Latency -Aware and Buffer -Based ABR algorithms \nunder the tested conditions (real HSDPA bandwidth + synthetic fluctuating delay):  \n1. Reduced Buffering:  The Latency -Aware (LA) algorithm demonstrated a substantial \nreduction in playback stalls, achieving an aver age buffering ratio approximately 60% \nlower than the Buffer -Based (BB) algorithm across the tested traces (13.8% vs 33.3%). \nThis indicates a significantly more stable and continuous viewing experience.  \n2. Improved Quality Stability:  The LA algorithm exhibited  vastly superior stability in \nbitrate selection, resulting in far fewer quality switches compared to the BB algorithm \n(average of 16 vs 114 switches per run). This contributes to a less visually jarring \nexperience for the user.  \n3. Lower Average Bitrate:  The i mproved stability of the LA algorithm came at the cost of a \nlower average delivered bitrate (826 kbps vs 2509 kbps for BB). The LA algorithm's",
    "metadata": {
      "source_file": "documents/Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1).pdf",
      "file_type": "pdf",
      "chunk_number": 0,
      "title": "Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1)",
      "file_size": 132671,
      "page_count": 4
    }
  },
  {
    "text": "erience for the user.  \n3. Lower Average Bitrate:  The i mproved stability of the LA algorithm came at the cost of a \nlower average delivered bitrate (826 kbps vs 2509 kbps for BB). The LA algorithm's\n\n[Page 2]\ntendency to be more conservative, accounting for potential download delays caused by \nRTT, prevented it from consi stently selecting the highest possible qualities available \nduring periods of high bandwidth.  \n4. Enhanced Estimated QoE:  Despite the lower average bitrate, the LA algorithm \nachieved a significantly better score on the simplified QoE metric ( -14.3 vs -50.7). Th is \nsuggests that, within this model, the penalties associated with frequent stalls and quality \nswitches outweighed the benefit of the higher average bitrate achieved by the BB \nalgorithm.  \n5. Confirmation of Latency Impact:  The marked difference in stability be tween the LA \n(delay -aware) and BB (delay -agnostic) algorithms, even with synthetic delay, strongly \nsupports the hypothesis that failing to account for network RTT significantly contributes \nto the instability of traditional ABR approaches in variable networ ks. \n5.3 Contributions of the Study  \nThis research makes the following contributions to the field of mobile video streaming \noptimization:  \n1. Demonstration of Latency -Aware Benefits:  It provides simulation -based evidence \ndemonstrating the feasibility and signifi cant stability advantages (reduced buffering, \nfewer quality switches) of an ABR algorithm that explicitly incorporates network delay \nestimations into its decision -making process.  \n2. Quantification under Semi -Realistic Conditions:  By utilizing real -world bandw idth \ntraces combined with controlled synthetic delay, the study offers a quantitative \ncomparison of latency -aware versus buffer -based strategies under conditions that reflect \ngenuine mobile bandwidth variability, going beyond purely synthetic network model s. \n3. Highlighting the Stability -Quality Trade -off: The results clearly quantify the inherent \ntrade -off between maximizing average bitrate and ensuring playback stability, providing \ndata points that inform the design of ABR algorithms aiming for optimal QoE.  \n4. Adaptable Simulation Framework:  The developed simulation code provides a flexible \nframework that can be extended to test more sophisticated ABR algorithms, incorporate \ndifferent network traces (including potentially complete traces with real delay), and \nmodel additional network phenomena.  \n5.4 Limitations of the Study  \nIt is essential to acknowledge the limitations of this study, which temper the generalizability of \nthe findings:  \n1. Synthetic Network Delay (Primary Limitation):  The inability to use real, synchro nized \nRTT delay data alongside the real bandwidth data is the most significant limitation. The \nsynthetic delay model, while incorporating fluctuations, cannot capture the true complex \npatterns, distributions, or potential correlations between real -world ba ndwidth and delay.",
    "metadata": {
      "source_file": "documents/Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1).pdf",
      "file_type": "pdf",
      "chunk_number": 1,
      "title": "Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1)",
      "file_size": 132671,
      "page_count": 4
    }
  },
  {
    "text": "limitation. The \nsynthetic delay model, while incorporating fluctuations, cannot capture the true complex \npatterns, distributions, or potential correlations between real -world ba ndwidth and delay.\n\n[Page 3]\nThe quantitative results are therefore dependent on the realism of this synthetic \ncomponent.  \n2. Dataset Characteristics:  The HSDPA bandwidth traces used are relatively old (2010 -\n2011) and represent 3G network technology. Modern 4G/LTE and 5 G networks exhibit \ndifferent characteristics, and the algorithms' performance might differ significantly on \ncontemporary networks.  \n3. Excluded Network Factors:  The simulation did not model the impact of packet loss or \nnetwork jitter, both of which can signifi cantly affect download times and QoE in real \nmobile networks.  \n4. Simplified ABR Algorithms:  The implemented LA algorithm uses basic prediction \n(Simple Moving Average). More advanced predictive models (e.g., ML -based) might \nyield different performance. Similarly, the BB algorithm is a simplified representation.  \n5. Simplified QoE Model:  The composite  QoE score is illustrative. Accurate QoE \nassessment requires subjective user testing to capture the complex human perception of \nvideo quality, stalls, and switches.  \n6. Simulation Fidelity:  No simulation can perfectly capture all aspects of real -world \nsystems,  including intricate TCP dynamics, client device processing limitations, or exact \nhandover behaviors.  \n5.5 Recommendations for Future Work  \nBased on the findings and limitations of this study, the following directions for future research \nare recommended:  \n1. Utilize Comprehensive Network Traces:  The highest priority is to acquire and utilize \ndatasets containing synchronized, real -world measurements of bandwidth, RTT delay, \npacket loss, and jitter  for contemporary mobile networks (4G/5G). Re -evaluating the \nLA algo rithm using such comprehensive data is crucial for robust validation.  \n2. Enhance Prediction Models:  Integrate and evaluate more sophisticated bandwidth and \ndelay prediction techniques within the LA ABR framework, potentially employing \nmachine learning models (LSTMs, etc.) as suggested in the methodology (Sec 3.3.2), to \nimprove accuracy and adaptation performance.  \n3. Incorporate Packet Loss and Jitter:  Extend the simulation model to include realistic \nmodels for packet loss and jitter and modify the ABR algorithms (particularly download \ntime estimation) to account for their impact.  \n4. Conduct Subjective QoE Studies:  Perform user studies comparing the LA and BB \nalgorithms under various network conditions (potentially emulated based on real traces) \nto obtain subjective M ean Opinion Scores (MOS) and validate the findings regarding \nuser-perceived quality and the stability/quality trade -off. \n5. Investigate Algorithm Parameter Tuning:  Explore methods for dynamically tuning the \nparameters of the LA algorithm (e.g., prediction win dow size, safety factor, conservatism \nthreshold) based on network conditions or user preferences.  \n6. Expand to VR/360 and Heterogeneity:  Adapt the latency -aware framework to address \nthe unique requirements of VR/360 streaming (ultra -low latency needs, viewpor t",
    "metadata": {
      "source_file": "documents/Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1).pdf",
      "file_type": "pdf",
      "chunk_number": 2,
      "title": "Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1)",
      "file_size": 132671,
      "page_count": 4
    }
  },
  {
    "text": "onditions or user preferences.  \n6. Expand to VR/360 and Heterogeneity:  Adapt the latency -aware framework to address \nthe unique requirements of VR/360 streaming (ultra -low latency needs, viewpor t\n\n[Page 4]\nprediction, tile -based streaming \u2013 Sec 1.2, 2.4.4, 3.3.2) and consider device \nheterogeneity (Sec 2.4.3).  \n7. Prototype Implementation and Testing:  Implement the LA algorithm in a real video \nplayer prototype (e.g., using DASH.js or a custom player) and test i ts performance on \nactual mobile devices over live networks.  \n5.6 Concluding Remarks  \nThis project successfully demonstrated, through simulation using real bandwidth traces, that \nincorporating awareness of network RTT delay into ABR decision -making can significantly \nenhance the stability of mobile video streaming compared to traditional buf fer-based methods. \nWhile the proposed Latency -Aware algorithm resulted in a lower average bitrate, its substantial \nreduction in playback stalls and quality switches led to a superior estimated Quality of \nExperience. The findings underscore the critical rol e of network delay in mobile streaming \nperformance and highlight the limitations of ABR strategies that primarily focus on bandwidth \noccupancy. Although constrained by the use of synthetic delay data, this study provides strong \nmotivation for developing an d validating more sophisticated latency -aware adaptation \ntechniques using comprehensive real -world network data. Addressing network latency \nproactively, rather than reactively through buffer management alone, holds significant promise \nfor delivering the se amless, high -quality viewing experiences demanded by users in the \nchallenging mobile environment.",
    "metadata": {
      "source_file": "documents/Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1).pdf",
      "file_type": "pdf",
      "chunk_number": 3,
      "title": "Chapter 5_ Analyzing and Optimizing Latency in Video Streaming(1)",
      "file_size": 132671,
      "page_count": 4
    }
  }
]